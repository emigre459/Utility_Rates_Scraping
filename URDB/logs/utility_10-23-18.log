2018-10-23 22:23:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: URDB)
2018-10-23 22:23:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-23 22:23:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'URDB', 'LOG_FILE': 'logs/utility_10-23-18.log', 'NEWSPIDER_MODULE': 'URDB.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['URDB.spiders'], 'USER_AGENT': 'Utility Rates Bot'}
2018-10-23 22:23:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-23 22:23:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-23 22:23:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-23 22:23:37 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-10-23 22:23:37 [scrapy.core.engine] INFO: Spider opened
2018-10-23 22:23:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-23 22:23:37 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.talquinelectric.com/robots.txt> from <GET http://www.talquinelectric.com/robots.txt>
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.iid.com/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.rrvcoop.com/robots.txt> from <GET http://www.rrvcoop.com/robots.txt>
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.prairielandelectric.com/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.midstateelectric.coop/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://villageofarcade.org/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.wakeforestnc.gov/robots.txt> from <GET http://www.wakeforestnc.gov/robots.txt>
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.iid.com/> from <GET http://www.iid.com>
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.mainepublicservice.com/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.surprisevalleyelectric.org/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.talquinelectric.com/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.mainepublicservice.com> (referer: None)
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.talquinelectric.com/> from <GET http://www.talquinelectric.com>
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rrvcoop.com/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.wakeforestnc.gov/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.rrvcoop.com/> from <GET http://www.rrvcoop.com>
2018-10-23 22:23:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.mainepublicservice.com>: HTTP status code is not handled or not allowed
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://singingriver.com/robots.txt> from <GET http://www.singingriver.com/robots.txt>
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.talquinelectric.com/> (referer: None)
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.wakeforestnc.gov/> from <GET http://www.wakeforestnc.gov>
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://psc.wi.gov/robots.txt> from <GET http://psc.wi.gov/robots.txt>
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.midstateelectric.coop> (referer: None)
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.prairielandelectric.com> (referer: None)
2018-10-23 22:23:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.talquinelectric.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://singingriver.com/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://villageofarcade.org> (referer: None)
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.ecirec.coop/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://singingriver.com/> from <GET http://www.singingriver.com>
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bartlettec.coop/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.midstateelectric.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.midstateelectric.coop.html'
2018-10-23 22:23:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.prairielandelectric.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.prairielandelectric.com.html'
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.delaware.coop/robots.txt> from <GET http://www.delaware.coop/robots.txt>
2018-10-23 22:23:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://villageofarcade.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-villageofarcade.org.html'
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.clatskaniepud.com/robots.txt> from <GET http://www.clatskaniepud.com/robots.txt>
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rrvcoop.com/> (referer: None)
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://singingriver.com/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.iid.com/> (referer: None)
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://singingriver.com/> from <GET http://singingriver.com/>
2018-10-23 22:23:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.rrvcoop.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.surprisevalleyelectric.org> (referer: None)
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sanpatricioelectric.org/robots.txt> from <GET http://www.sanpatricioelectric.org/robots.txt>
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://psc.wi.gov/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.iid.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.clatskaniepud.com/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.surprisevalleyelectric.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.surprisevalleyelectric.org.html'
2018-10-23 22:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.delaware.coop/robots.txt> (referer: None)
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://psc.wi.gov/> from <GET http://psc.wi.gov>
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.clatskaniepud.com/> from <GET http://www.clatskaniepud.com>
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.npec.org/robots.txt> from <GET http://www.npec.org/robots.txt>
2018-10-23 22:23:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.delaware.coop/> from <GET http://www.delaware.coop>
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.neelectric.com/robots.txt> (referer: None)
2018-10-23 22:23:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://psc.wi.gov/Pages/Home.aspx> from <GET https://psc.wi.gov/>
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ecirec.coop> (referer: None)
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.clatskaniepud.com/> (referer: None)
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.delaware.coop/> (referer: None)
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://singingriver.com/> (referer: None)
2018-10-23 22:23:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sfwater.org/robots.txt> from <GET http://sfwater.org/robots.txt>
2018-10-23 22:23:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.ecirec.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.ecirec.coop.html'
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://psc.wi.gov/Pages/Home.aspx> (referer: None)
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sanpatricioelectric.org/robots.txt> (referer: None)
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.brmemc.com/robots.txt> (referer: None)
2018-10-23 22:23:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.clatskaniepud.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.delaware.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cme.coop/robots.txt> (referer: None)
2018-10-23 22:23:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://singingriver.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sanpatricioelectric.org/> from <GET http://www.sanpatricioelectric.org>
2018-10-23 22:23:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://psc.wi.gov/Pages/Home.aspx> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-Home.aspx.html'
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.neelectric.com> (referer: None)
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cme.coop> (referer: None)
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.brmemc.com> (referer: None)
2018-10-23 22:23:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.neelectric.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.neelectric.com.html'
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.wakeforestnc.gov/> (referer: None)
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.iplpower.com/robots.txt> (referer: None)
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.iclp.coop/robots.txt> (referer: None)
2018-10-23 22:23:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://lodielectric.com/robots.txt> (failed 1 times): DNS lookup failed: no results for hostname lookup: lodielectric.com.
2018-10-23 22:23:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://lodielectric.com/robots.txt> (failed 2 times): DNS lookup failed: no results for hostname lookup: lodielectric.com.
2018-10-23 22:23:39 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://lodielectric.com/robots.txt> (failed 3 times): DNS lookup failed: no results for hostname lookup: lodielectric.com.
2018-10-23 22:23:39 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://lodielectric.com/robots.txt>: DNS lookup failed: no results for hostname lookup: lodielectric.com.
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: lodielectric.com.
2018-10-23 22:23:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cme.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cme.coop.html'
2018-10-23 22:23:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.brmemc.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.brmemc.com.html'
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.claycountyelectric.com/robots.txt> (referer: None)
2018-10-23 22:23:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://lodielectric.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: lodielectric.com.
2018-10-23 22:23:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.iplpower.com/> from <GET http://www.iplpower.com>
2018-10-23 22:23:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://lodielectric.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: lodielectric.com.
2018-10-23 22:23:39 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://lodielectric.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: lodielectric.com.
2018-10-23 22:23:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.wakeforestnc.gov/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.claycountyelectric.com> (referer: None)
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sanpatricioelectric.org/> (referer: None)
2018-10-23 22:23:39 [scrapy.core.scraper] ERROR: Error downloading <GET http://lodielectric.com>
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: lodielectric.com.
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.morristownutilities.org/robots.txt> (referer: None)
2018-10-23 22:23:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.claycountyelectric.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.claycountyelectric.com.html'
2018-10-23 22:23:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.sanpatricioelectric.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.adrian.govoffice2.com/robots.txt> (referer: None) ['partial']
2018-10-23 22:23:39 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://www.adrian.govoffice2.com>
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.swepco.com/robots.txt> (referer: None)
2018-10-23 22:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.npec.org/robots.txt> (referer: None)
2018-10-23 22:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.iplpower.com/> (referer: None)
2018-10-23 22:23:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.iplpower.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.npec.org/> from <GET http://www.npec.org>
2018-10-23 22:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.iclp.coop> (referer: None)
2018-10-23 22:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.swepco.com> (referer: None)
2018-10-23 22:23:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.bartlettec.coop/> from <GET http://www.bartlettec.coop>
2018-10-23 22:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.morristownutilities.org> (referer: None)
2018-10-23 22:23:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.iclp.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.iclp.coop.html'
2018-10-23 22:23:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.statesvillenc.net/robots.txt> from <GET http://www.ci.statesville.nc.us/robots.txt>
2018-10-23 22:23:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.swepco.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.swepco.com.html'
2018-10-23 22:23:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.morristownutilities.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.morristownutilities.org.html'
2018-10-23 22:23:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.avistautilities.com/robots.txt> from <GET http://www.avistautilities.com/robots.txt>
2018-10-23 22:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nli.coop/robots.txt> (referer: None)
2018-10-23 22:23:40 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://sfwater.org/robots.txt> (referer: None)
2018-10-23 22:23:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.nli.coop/> from <GET http://www.nli.coop>
2018-10-23 22:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ssemc.com/robots.txt> (referer: None)
2018-10-23 22:23:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sfwater.org/> from <GET http://sfwater.org>
2018-10-23 22:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.statesvillenc.net/robots.txt> (referer: None)
2018-10-23 22:23:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://jocarroll.coopwebbuilder2.com/robots.txt> from <GET http://jocarroll.coopwebbuilder2.com/robots.txt>
2018-10-23 22:23:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.statesvillenc.net/> from <GET http://www.ci.statesville.nc.us>
2018-10-23 22:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.statesvillenc.net/robots.txt> (referer: None)
2018-10-23 22:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ssemc.com> (referer: None)
2018-10-23 22:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bancroftiowa.com/robots.txt> (referer: None) ['partial']
2018-10-23 22:23:40 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://bancroftiowa.com>
2018-10-23 22:23:40 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "jocarroll.coopwebbuilder2.com"; VerificationError(errors=[DNSMismatch(mismatched_id=DNS_ID(hostname=b'jocarroll.coopwebbuilder2.com'))])
2018-10-23 22:23:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.ssemc.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.ssemc.com.html'
2018-10-23 22:23:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jocarroll.coopwebbuilder2.com/robots.txt> (referer: None)
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sfwater.org/> (referer: None)
2018-10-23 22:23:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://jocarroll.coopwebbuilder2.com/> from <GET http://jocarroll.coopwebbuilder2.com>
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.nli.coop/> (referer: None)
2018-10-23 22:23:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://westcentralelectric.coop/robots.txt> from <GET http://westcentralelectric.coop/robots.txt>
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.statesvillenc.net/> (referer: None)
2018-10-23 22:23:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sfwater.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.npec.org/> (referer: None)
2018-10-23 22:23:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.myavista.com> from <GET https://www.avistautilities.com/robots.txt>
2018-10-23 22:23:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nli.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.statesvillenc.net/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.npec.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://westcentralelectric.coop/robots.txt> (referer: None)
2018-10-23 22:23:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.volgacity.com/robots.txt> from <GET http://www.volgacity.com/robots.txt>
2018-10-23 22:23:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://westcentralelectric.coop/> from <GET http://westcentralelectric.coop>
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://milford.ia.us/robots.txt> (referer: None)
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bartlettec.coop/> (referer: None)
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jocarroll.coopwebbuilder2.com/> (referer: None)
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://jcremc.com/robots.txt> (referer: None)
2018-10-23 22:23:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bartlettec.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jocarroll.coopwebbuilder2.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sce.com/robots.txt> from <GET http://www.sce.com/robots.txt>
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.volgacity.com/robots.txt> (referer: None)
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.entergy-texas.com/robots.txt> (referer: None)
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://westcentralelectric.coop/> (referer: None)
2018-10-23 22:23:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.pacificpower.net/robots.txt> from <GET http://www.pacificpower.net/robots.txt>
2018-10-23 22:23:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.volgacity.com/> from <GET http://www.volgacity.com>
2018-10-23 22:23:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://westcentralelectric.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://edmondok.com/robots.txt> (referer: None)
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sce.com/robots.txt> (referer: None)
2018-10-23 22:23:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://jcremc.com/> from <GET http://jcremc.com>
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nfecoop.com/robots.txt> (referer: None)
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pacificpower.net/robots.txt> (referer: None)
2018-10-23 22:23:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sce.com/wps/portal/> from <GET http://www.sce.com>
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.entergy-texas.com> (referer: None)
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.sepb.net/robots.txt> (referer: None)
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.myavista.com> (referer: None)
2018-10-23 22:23:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.entergy-texas.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.entergy-texas.com.html'
2018-10-23 22:23:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.avistautilities.com/> from <GET http://www.avistautilities.com>
2018-10-23 22:23:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.spec.coop/robots.txt> from <GET http://www.spec.coop/robots.txt>
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lacreek.com/robots.txt> (referer: None)
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.columbusco-op.org/robots.txt> (referer: None)
2018-10-23 22:23:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sce.com/wps/portal/home/!ut/p/b0/04_Sj9CPykssy0xPLMnMz0vMAfGjzOIt3Q1cPbz8DTzdQwKNDTyNAw38gh0djQ0MzPQLsh0VAdgL0go!/> from <GET https://www.sce.com/wps/portal/>
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nfecoop.com> (referer: None)
2018-10-23 22:23:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.myavista.com> from <GET https://www.avistautilities.com/>
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://edmondok.com> (referer: None)
2018-10-23 22:23:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.nfecoop.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.nfecoop.com.html'
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.spec.coop/robots.txt> (referer: None)
2018-10-23 22:23:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://longmontcolorado.gov> from <GET http://www.ci.longmont.co.us/robots.txt>
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.myavista.com/robots.txt> (referer: None)
2018-10-23 22:23:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://edmondok.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-edmondok.com.html'
2018-10-23 22:23:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.spec.coop/> from <GET http://www.spec.coop>
2018-10-23 22:23:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.longmontcolorado.gov/> from <GET http://longmontcolorado.gov>
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lacreek.com> (referer: None)
2018-10-23 22:23:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.vernonelectric.org/robots.txt> (referer: None)
2018-10-23 22:23:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://milford.ia.us/> from <GET http://milford.ia.us>
2018-10-23 22:23:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.lacreek.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.lacreek.com.html'
2018-10-23 22:23:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.longmontcolorado.gov/> from <GET http://www.longmontcolorado.gov/>
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jcremc.com/> (referer: None)
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sce.com/wps/portal/home/!ut/p/b0/04_Sj9CPykssy0xPLMnMz0vMAfGjzOIt3Q1cPbz8DTzdQwKNDTyNAw38gh0djQ0MzPQLsh0VAdgL0go!/> (referer: None)
2018-10-23 22:23:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jcremc.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.sce.com/wps/portal/home/!ut/p/b0/04_Sj9CPykssy0xPLMnMz0vMAfGjzOIt3Q1cPbz8DTzdQwKNDTyNAw38gh0djQ0MzPQLsh0VAdgL0go!/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sepb.net/> from <GET http://www.sepb.net>
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.spec.coop/> (referer: None)
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.myavista.com> (referer: None)
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.vernonelectric.org> (referer: None)
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.columbusco-op.org> (referer: None)
2018-10-23 22:23:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.pbutilities.com/robots.txt> from <GET http://www.pbutilities.com/robots.txt>
2018-10-23 22:23:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.spec.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.myavista.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.myavista.com.html'
2018-10-23 22:23:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.vernonelectric.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.vernonelectric.org.html'
2018-10-23 22:23:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.columbusco-op.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.columbusco-op.org.html'
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.osagecity.com/robots.txt> (referer: None)
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.volgacity.com/> (referer: None)
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.trico.coop/robots.txt> (referer: None)
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.longmontcolorado.gov/> (referer: None)
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.holden-ma.gov/robots.txt> (referer: None)
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.pbutilities.com/robots.txt> (referer: None)
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.holden-ma.gov> (referer: None)
2018-10-23 22:23:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.volgacity.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.pbutilities.com/> from <GET http://www.pbutilities.com>
2018-10-23 22:23:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.holden-ma.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.holden-ma.gov.html'
2018-10-23 22:23:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://longmontcolorado.gov> from <GET http://www.ci.longmont.co.us>
2018-10-23 22:23:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.longmontcolorado.gov/robots.txt> from <GET http://longmontcolorado.gov/robots.txt>
2018-10-23 22:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.hawkeyerec.com/robots.txt> (referer: None)
2018-10-23 22:23:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.blackhillsenergy.com/robots.txt> from <GET http://www.cheyennelight.com/robots.txt>
2018-10-23 22:23:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.mwenergy.com/robots.txt> from <GET http://www.mwenergy.com/robots.txt>
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.trico.coop> (referer: None)
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.longmontcolorado.gov/robots.txt> (referer: None)
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.hawkeyerec.com> (referer: None)
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.longmontcolorado.gov/> from <GET http://longmontcolorado.gov>
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.longmontcolorado.gov/robots.txt> (referer: None)
2018-10-23 22:23:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.trico.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.trico.coop.html'
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pbutilities.com/> (referer: None)
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.osagecity.com> (referer: None)
2018-10-23 22:23:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.hawkeyerec.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.hawkeyerec.com.html'
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.longmontcolorado.gov/> from <GET http://www.longmontcolorado.gov/>
2018-10-23 22:23:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pbutilities.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.osagecity.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.osagecity.com.html'
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mwenergy.com/robots.txt> (referer: None)
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.blackhillsenergy.com/robots.txt> (referer: None)
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://aemc.coop/robots.txt> (referer: None)
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.dmea.com/robots.txt> (referer: None)
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.blackhillsenergy.com/> from <GET http://www.cheyennelight.com>
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://publicutilities.columbus.gov/robots.txt> (failed 1 times): DNS lookup failed: no results for hostname lookup: publicutilities.columbus.gov.
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://publicutilities.columbus.gov/robots.txt> (failed 2 times): DNS lookup failed: no results for hostname lookup: publicutilities.columbus.gov.
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://publicutilities.columbus.gov/robots.txt> (failed 3 times): DNS lookup failed: no results for hostname lookup: publicutilities.columbus.gov.
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://publicutilities.columbus.gov/robots.txt>: DNS lookup failed: no results for hostname lookup: publicutilities.columbus.gov.
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: publicutilities.columbus.gov.
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://publicutilities.columbus.gov> (failed 1 times): DNS lookup failed: no results for hostname lookup: publicutilities.columbus.gov.
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://publicutilities.columbus.gov> (failed 2 times): DNS lookup failed: no results for hostname lookup: publicutilities.columbus.gov.
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://publicutilities.columbus.gov> (failed 3 times): DNS lookup failed: no results for hostname lookup: publicutilities.columbus.gov.
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.mwenergy.com/> from <GET http://www.mwenergy.com>
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.clarkpublicutilities.com/robots.txt> from <GET http://www.clarkpublicutilities.com/robots.txt>
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.blackhillsenergy.com/robots.txt> (referer: None)
2018-10-23 22:23:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://publicutilities.columbus.gov>
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: publicutilities.columbus.gov.
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.losalamosnm.us/robots.txt/> from <GET http://www.losalamosnm.us/robots.txt>
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.losalamosnm.us/robots.txt/Default.aspx> from <GET http://www.losalamosnm.us/robots.txt/>
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.losalamosnm.us/robots.txt/Default.aspx> (referer: None)
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://aemc.coop> (referer: None)
2018-10-23 22:23:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://aemc.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-aemc.coop.html'
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofhoward.com/robots.txt> (referer: None) ['partial']
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://www.cityofhoward.com>
2018-10-23 22:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.clarkpublicutilities.com/robots.txt> (referer: None)
2018-10-23 22:23:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.clarkpublicutilities.com/> from <GET http://www.clarkpublicutilities.com>
2018-10-23 22:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.longmontcolorado.gov/> (referer: None)
2018-10-23 22:23:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.longmontcolorado.gov/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.moreno-valley.ca.us/robots.txt> (referer: None)
2018-10-23 22:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.clarkpublicutilities.com/> (referer: None)
2018-10-23 22:23:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.clarkpublicutilities.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lcpd1.com/robots.txt> (referer: None)
2018-10-23 22:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sepb.net/> (referer: None)
2018-10-23 22:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.pud-ri.org/robots.txt> (referer: None)
2018-10-23 22:23:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (meta refresh) to <GET http://www.moval.org/index.shtml> from <GET http://www.moreno-valley.ca.us>
2018-10-23 22:23:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.sepb.net/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.losalamosnm.us> (referer: None)
2018-10-23 22:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mwenergy.com/> (referer: None)
2018-10-23 22:23:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.alputilities.com/robots.txt> from <GET http://www.alputilities.com/robots.txt>
2018-10-23 22:23:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.losalamosnm.us> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.losalamosnm.us.html'
2018-10-23 22:23:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.mwenergy.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.blackhillsenergy.com/> (referer: None)
2018-10-23 22:23:45 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://billing.pve.coop/robots.txt> (referer: None)
2018-10-23 22:23:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (meta refresh) to <GET https://billing.pve.coop/oscp/> from <GET https://billing.pve.coop>
2018-10-23 22:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.moval.org/robots.txt> (referer: None)
2018-10-23 22:23:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.blackhillsenergy.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.pickwick-electric.com/robots.txt> (referer: None)
2018-10-23 22:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lcpd1.com> (referer: None)
2018-10-23 22:23:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.pickwickec.com> from <GET http://www.pickwick-electric.com>
2018-10-23 22:23:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.lcpd1.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.lcpd1.com.html'
2018-10-23 22:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.moval.org/index.shtml> (referer: None)
2018-10-23 22:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.swec-coop.org/robots.txt> (referer: None)
2018-10-23 22:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofplattsburgh-ny.gov/robots.txt> (referer: None)
2018-10-23 22:23:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moval.org/index.shtml> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-index.shtml.html'
2018-10-23 22:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityoflexington.com/robots.txt> (referer: None)
2018-10-23 22:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.dmea.com> (referer: None)
2018-10-23 22:23:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dmea.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.dmea.com.html'
2018-10-23 22:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.alputilities.com/robots.txt> (referer: None)
2018-10-23 22:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.swec-coop.org> (referer: None)
2018-10-23 22:23:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.alputilities.com/> from <GET http://www.alputilities.com>
2018-10-23 22:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.lbwl.com/robots.txt> (referer: None)
2018-10-23 22:23:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.swec-coop.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.swec-coop.org.html'
2018-10-23 22:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.pud-ri.org> (referer: None)
2018-10-23 22:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.salemelectric.com/robots.txt> (referer: None)
2018-10-23 22:23:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.cityoflexington.com/> from <GET http://www.cityoflexington.com>
2018-10-23 22:23:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.salemelectric.com/> from <GET http://www.salemelectric.com>
2018-10-23 22:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.alputilities.com/> (referer: None)
2018-10-23 22:23:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.pud-ri.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.pud-ri.org.html'
2018-10-23 22:23:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.alputilities.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://rrelectric.coopwebbuilder2.com/robots.txt> (referer: None)
2018-10-23 22:23:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofplattsburgh-ny.gov> (referer: None)
2018-10-23 22:23:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.salemelectric.com/> (referer: None)
2018-10-23 22:23:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nppd.com/robots.txt> (referer: None)
2018-10-23 22:23:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cityofplattsburgh-ny.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cityofplattsburgh-ny.gov.html'
2018-10-23 22:23:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.salemelectric.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://milford.ia.us/> (referer: None)
2018-10-23 22:23:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://rrelectric.coopwebbuilder2.com> (referer: None)
2018-10-23 22:23:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://milford.ia.us/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.nppd.com/> from <GET http://www.nppd.com>
2018-10-23 22:23:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.breckenridgemn.net/robots.txt> (failed 1 times): DNS lookup failed: no results for hostname lookup: www.breckenridgemn.net.
2018-10-23 22:23:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://rrelectric.coopwebbuilder2.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-rrelectric.coopwebbuilder2.com.html'
2018-10-23 22:23:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.breckenridgemn.net/robots.txt> (failed 2 times): DNS lookup failed: no results for hostname lookup: www.breckenridgemn.net.
2018-10-23 22:23:47 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.breckenridgemn.net/robots.txt> (failed 3 times): DNS lookup failed: no results for hostname lookup: www.breckenridgemn.net.
2018-10-23 22:23:47 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.breckenridgemn.net/robots.txt>: DNS lookup failed: no results for hostname lookup: www.breckenridgemn.net.
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.breckenridgemn.net.
2018-10-23 22:23:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.breckenridgemn.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: www.breckenridgemn.net.
2018-10-23 22:23:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.breckenridgemn.net> (failed 2 times): DNS lookup failed: no results for hostname lookup: www.breckenridgemn.net.
2018-10-23 22:23:47 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.breckenridgemn.net> (failed 3 times): DNS lookup failed: no results for hostname lookup: www.breckenridgemn.net.
2018-10-23 22:23:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cityoflexington.com/> (referer: None)
2018-10-23 22:23:47 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.breckenridgemn.net>
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.breckenridgemn.net.
2018-10-23 22:23:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://billing.pve.coop/oscp/BrowserNotSupported.aspx> from <GET https://billing.pve.coop/oscp/>
2018-10-23 22:23:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.seattle.gov/robots.txt> (referer: None)
2018-10-23 22:23:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cityoflexington.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://billing.pve.coop/oscp/BrowserNotSupported.aspx> (referer: None)
2018-10-23 22:23:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eastpointcity.org/robots.txt> (referer: None)
2018-10-23 22:23:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://billing.pve.coop/oscp/BrowserNotSupported.aspx> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-BrowserNotSupported.aspx.html'
2018-10-23 22:23:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.gulfpower.com/robots.txt> from <GET http://www.gulfpower.com/robots.txt>
2018-10-23 22:23:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.seattle.gov> (referer: None)
2018-10-23 22:23:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.seattle.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.seattle.gov.html'
2018-10-23 22:23:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.eastpointcity.org> (referer: None)
2018-10-23 22:23:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.lbwl.com> (referer: None)
2018-10-23 22:23:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.belw.org/robots.txt> (referer: None)
2018-10-23 22:23:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.pacificpower.net/> from <GET http://www.pacificpower.net>
2018-10-23 22:23:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.fcpud.com/robots.txt> (referer: None)
2018-10-23 22:23:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.eastpointcity.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.eastpointcity.org.html'
2018-10-23 22:23:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.gulfpower.com/robots.txt> (referer: None)
2018-10-23 22:23:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.lbwl.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.lbwl.com.html'
2018-10-23 22:23:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.gulfpower.com/> from <GET http://www.gulfpower.com>
2018-10-23 22:23:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.pacificpower.net/index.html> from <GET https://www.pacificpower.net/>
2018-10-23 22:23:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.chelanpud.org/robots.txt> (referer: None)
2018-10-23 22:23:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.nppd.com/> (referer: None)
2018-10-23 22:23:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.meckelec.org/robots.txt> (referer: None)
2018-10-23 22:23:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.gulfpower.com/> (referer: None)
2018-10-23 22:23:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nppd.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.meckelec.org> (referer: None)
2018-10-23 22:23:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.gulfpower.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pacificpower.net/index.html> (referer: None)
2018-10-23 22:23:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ci.madison.mn.us/robots.txt> (referer: None)
2018-10-23 22:23:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.cityofpaloalto.org/robots.txt> from <GET http://www.cityofpaloalto.org/robots.txt>
2018-10-23 22:23:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.meckelec.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.meckelec.org.html'
2018-10-23 22:23:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pacificpower.net/index.html> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-index.html.html'
2018-10-23 22:23:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.ci.madison.mn.us/> from <GET http://www.ci.madison.mn.us>
2018-10-23 22:23:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofvernon.org/robots.txt> (referer: None)
2018-10-23 22:23:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.belw.org> (referer: None)
2018-10-23 22:23:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.belw.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.belw.org.html'
2018-10-23 22:23:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ci.madison.mn.us/> (referer: None)
2018-10-23 22:23:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.pickwickec.com/robots.txt> (referer: None)
2018-10-23 22:23:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ci.madison.mn.us/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cityofpaloalto.org/robots.txt> (referer: None)
2018-10-23 22:23:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://des.dmcsdev.com/robots.txt> (failed 1 times): DNS lookup failed: no results for hostname lookup: des.dmcsdev.com.
2018-10-23 22:23:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://des.dmcsdev.com/robots.txt> (failed 2 times): DNS lookup failed: no results for hostname lookup: des.dmcsdev.com.
2018-10-23 22:23:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.cityofpaloalto.org/> from <GET http://www.cityofpaloalto.org>
2018-10-23 22:23:49 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://des.dmcsdev.com/robots.txt> (failed 3 times): DNS lookup failed: no results for hostname lookup: des.dmcsdev.com.
2018-10-23 22:23:49 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://des.dmcsdev.com/robots.txt>: DNS lookup failed: no results for hostname lookup: des.dmcsdev.com.
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: des.dmcsdev.com.
2018-10-23 22:23:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://des.dmcsdev.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: des.dmcsdev.com.
2018-10-23 22:23:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://des.dmcsdev.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: des.dmcsdev.com.
2018-10-23 22:23:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofvernon.org> (referer: None)
2018-10-23 22:23:49 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://des.dmcsdev.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: des.dmcsdev.com.
2018-10-23 22:23:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://fcpud.com/> from <GET http://www.fcpud.com>
2018-10-23 22:23:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.npec.org/robots.txt> from <GET http://npec.org/robots.txt>
2018-10-23 22:23:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cityofvernon.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cityofvernon.org.html'
2018-10-23 22:23:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://des.dmcsdev.com>
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: des.dmcsdev.com.
2018-10-23 22:23:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://gcea.coopwebbuilder2.com/robots.txt> (referer: None)
2018-10-23 22:23:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://riversideca.gov/robots.txt> from <GET http://www.riversideca.gov/robots.txt>
2018-10-23 22:23:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sgcity.org/robots.txt> from <GET http://www.sgcity.org/robots.txt>
2018-10-23 22:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://gcea.coopwebbuilder2.com> (referer: None)
2018-10-23 22:23:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://gcea.coopwebbuilder2.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-gcea.coopwebbuilder2.com.html'
2018-10-23 22:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.npec.org/robots.txt> (referer: None)
2018-10-23 22:23:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.npec.org/> from <GET http://npec.org>
2018-10-23 22:23:50 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://www.npec.org/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-23 22:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fcpud.com/robots.txt> (referer: None)
2018-10-23 22:23:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sgcity.org/search/robots.txt> from <GET https://www.sgcity.org/robots.txt>
2018-10-23 22:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://riversideca.gov/robots.txt> (referer: None)
2018-10-23 22:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fcpud.com/> (referer: None)
2018-10-23 22:23:50 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://mgemc.coopwebbuilder2.com/robots.txt> (referer: None)
2018-10-23 22:23:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://riversideca.gov/> from <GET http://www.riversideca.gov>
2018-10-23 22:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.pickwickec.com> (referer: None)
2018-10-23 22:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://mgemc.coopwebbuilder2.com> (referer: None)
2018-10-23 22:23:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://fcpud.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sbunet.com/robots.txt> from <GET http://www.sbunet.com/robots.txt>
2018-10-23 22:23:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.pickwickec.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.pickwickec.com.html'
2018-10-23 22:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://riversideca.gov/robots.txt> (referer: None)
2018-10-23 22:23:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://mgemc.coopwebbuilder2.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-mgemc.coopwebbuilder2.com.html'
2018-10-23 22:23:51 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.town.wallingford.ct.us/robots.txt> (referer: None)
2018-10-23 22:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sgcity.org/search/robots.txt> (referer: None)
2018-10-23 22:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://riversideca.gov/> (referer: None)
2018-10-23 22:23:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://riversideca.gov/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sgcity.org/> from <GET http://www.sgcity.org>
2018-10-23 22:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sbunet.com/robots.txt> (referer: None)
2018-10-23 22:23:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sbunet.com/> from <GET http://www.sbunet.com>
2018-10-23 22:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.indianamichiganpower.com/robots.txt> (referer: None)
2018-10-23 22:23:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://butlerppd.com/robots.txt> from <GET http://www.butlerppd.com/robots.txt>
2018-10-23 22:23:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sgcity.org/> (referer: None)
2018-10-23 22:23:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.sgcity.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.indianamichiganpower.com> (referer: None)
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofmarshall.com/robots.txt> (referer: None)
2018-10-23 22:23:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.indianamichiganpower.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.indianamichiganpower.com.html'
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://butlerppd.com/robots.txt> (referer: None)
2018-10-23 22:23:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.duke-energy.com/robots.txt> from <GET http://www.duke-energy.com/robots.txt>
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.town.wallingford.ct.us> (referer: None)
2018-10-23 22:23:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://butlerppd.com/> from <GET http://www.butlerppd.com>
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://butlerppd.com/robots.txt> (referer: None)
2018-10-23 22:23:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.town.wallingford.ct.us> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.town.wallingford.ct.us.html'
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://butlerppd.com/> (referer: None)
2018-10-23 22:23:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://butlerppd.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.duke-energy.com/robots.txt> (referer: None)
2018-10-23 22:23:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://library.municode.com/robots.txt> from <GET http://library.municode.com/robots.txt>
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ayden.com/robots.txt> (referer: None)
2018-10-23 22:23:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.duke-energy.com/> from <GET http://www.duke-energy.com>
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.linncountyrec.com/robots.txt> (referer: None)
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.keysenergy.com/robots.txt> (referer: None)
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://library.municode.com/robots.txt> (referer: None)
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sbunet.com/> (referer: None)
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.gladstonemi.org/robots.txt> (referer: None)
2018-10-23 22:23:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://library.municode.com/> from <GET http://library.municode.com>
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://library.municode.com> (referer: None)
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ayden.com> (referer: None)
2018-10-23 22:23:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.sbunet.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.gladstonemi.org> (referer: None)
2018-10-23 22:23:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://library.municode.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-library.municode.com.html'
2018-10-23 22:23:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.ayden.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.ayden.com.html'
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.keysenergy.com> (referer: None)
2018-10-23 22:23:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gladstonemi.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.gladstonemi.org.html'
2018-10-23 22:23:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.keysenergy.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.keysenergy.com.html'
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.sullivanil.us/robots.txt> (referer: None)
2018-10-23 22:23:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.mcrea.org/robots.txt> from <GET http://www.mcrea.org/robots.txt>
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.sullivanil.us> (referer: None)
2018-10-23 22:23:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.midamericanenergy.com/robots.txt> from <GET http://www.midamericanenergy.com/robots.txt>
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.linncountyrec.com> (referer: None)
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.arlingtonmn.com/robots.txt> (referer: None)
2018-10-23 22:23:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.sullivanil.us> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.sullivanil.us.html'
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://cityofpa.us/robots.txt> (referer: None)
2018-10-23 22:23:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.linncountyrec.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.linncountyrec.com.html'
2018-10-23 22:23:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.duke-energy.com/home> from <GET https://www.duke-energy.com/>
2018-10-23 22:23:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.arlingtonmn.com/> from <GET http://www.arlingtonmn.com>
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cityofpaloalto.org/> (referer: None)
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.sussexrec.com/robots.txt> (referer: None)
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.frederickok.org/robots.txt> (referer: None)
2018-10-23 22:23:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cityofpaloalto.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mcrea.org/robots.txt> (referer: None)
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.chelanpud.org> (referer: None)
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.arlingtonmn.com/> (referer: None)
2018-10-23 22:23:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.mcrea.org/> from <GET http://www.mcrea.org>
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.frederickok.org> (referer: None)
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://facts.psc.state.ga.us/robots.txt> (referer: None)
2018-10-23 22:23:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.chelanpud.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.chelanpud.org.html'
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.midamericanenergy.com/robots.txt> (referer: None)
2018-10-23 22:23:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.arlingtonmn.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.frederickok.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.frederickok.org.html'
2018-10-23 22:23:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://facts.psc.state.ga.us/Public/Default.aspx> from <GET http://facts.psc.state.ga.us>
2018-10-23 22:23:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.midamericanenergy.com/> from <GET http://www.midamericanenergy.com>
2018-10-23 22:23:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.sussexrec.com> (referer: None)
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.beld.com/robots.txt> (referer: None)
2018-10-23 22:23:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.wascoelectric.com/robots.txt> from <GET http://www.wascoelectric.com/robots.txt>
2018-10-23 22:23:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.ci.azusa.ca.us/robots.txt> from <GET http://www.ci.azusa.ca.us/robots.txt>
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.midamericanenergy.com/> (referer: None)
2018-10-23 22:23:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.sussexrec.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.sussexrec.com.html'
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://facts.psc.state.ga.us/Public/Default.aspx> (referer: None)
2018-10-23 22:23:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.midamericanenergy.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://facts.psc.state.ga.us/Public/Default.aspx> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-Default.aspx.html'
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.beld.com> (referer: None)
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.duke-energy.com/home> (referer: None)
2018-10-23 22:23:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.cmec.coop/robots.txt> from <GET http://www.cmec.coop/robots.txt>
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mcrea.org/> (referer: None)
2018-10-23 22:23:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.beld.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.beld.com.html'
2018-10-23 22:23:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.duke-energy.com/home> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-home.html'
2018-10-23 22:23:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.mcrea.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ci.azusa.ca.us/robots.txt> (referer: None)
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://cityofpa.us> (referer: None)
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.wascoelectric.com/robots.txt> (referer: None)
2018-10-23 22:23:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.ci.azusa.ca.us/> from <GET http://www.ci.azusa.ca.us>
2018-10-23 22:23:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://cityofpa.us> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-cityofpa.us.html'
2018-10-23 22:23:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.wascoelectric.com/> from <GET http://www.wascoelectric.com>
2018-10-23 22:23:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.custerpower.com/robots.txt> from <GET http://www.custerpower.com/robots.txt>
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bcremc.com/robots.txt> (referer: None)
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.wascoelectric.com/> (referer: None)
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.mub-albertville.com/robots.txt> (referer: None)
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.custerpower.com/robots.txt> (referer: None)
2018-10-23 22:23:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.custerpower.com/> from <GET http://www.custerpower.com>
2018-10-23 22:23:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.wascoelectric.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.mcpbpu.com/robots.txt> (referer: None)
2018-10-23 22:23:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.bcremc.com/> from <GET http://www.bcremc.com>
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.custerpower.com/> (referer: None)
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.mcpbpu.com> (referer: None)
2018-10-23 22:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofmarshall.com> (referer: None)
2018-10-23 22:23:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.custerpower.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.mcpbpu.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.mcpbpu.com.html'
2018-10-23 22:23:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cityofmarshall.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cityofmarshall.com.html'
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.fpunet.com/robots.txt> (referer: None)
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cmec.coop/robots.txt> (referer: None)
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.tcemc.org/robots.txt> (referer: None)
2018-10-23 22:23:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.cmec.coop/> from <GET http://www.cmec.coop>
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bcremc.com/> (referer: None)
2018-10-23 22:23:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sciremc.com/robots.txt> from <GET http://www.sciremc.com/robots.txt>
2018-10-23 22:23:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bcremc.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ci.azusa.ca.us/> (referer: None)
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.mub-albertville.com> (referer: None)
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.tcemc.org> (referer: None)
2018-10-23 22:23:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://erppd.com/robots.txt> from <GET http://www.erppd.com/robots.txt>
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.fpunet.com> (referer: None)
2018-10-23 22:23:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ci.azusa.ca.us/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.easleyutilities.com/robots.txt> from <GET http://www.easleyutilities.com/robots.txt>
2018-10-23 22:23:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.mub-albertville.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.mub-albertville.com.html'
2018-10-23 22:23:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.tcemc.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.tcemc.org.html'
2018-10-23 22:23:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.fpunet.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.fpunet.com.html'
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sciremc.com/robots.txt> (referer: None)
2018-10-23 22:23:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://trf.mncable.net/robots.txt> from <GET http://mncable.net/robots.txt>
2018-10-23 22:23:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sciremc.com/> from <GET http://www.sciremc.com>
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.easleyutilities.com/robots.txt> (referer: None)
2018-10-23 22:23:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.easleyutilities.com/> from <GET http://www.easleyutilities.com>
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://erppd.com/robots.txt> (referer: None)
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://trf.mncable.net/robots.txt> (referer: None)
2018-10-23 22:23:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://erppd.com/> from <GET http://www.erppd.com>
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.easleyutilities.com/> (referer: None)
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://erppd.com/robots.txt> (referer: None)
2018-10-23 22:23:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://trf.mncable.net/> from <GET http://mncable.net>
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://erppd.com/> (referer: None)
2018-10-23 22:23:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.mitchellcity.net/robots.txt> from <GET http://www.mitchellcity.net/robots.txt>
2018-10-23 22:23:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.easleyutilities.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://trf.mncable.net/robots.txt> (referer: None)
2018-10-23 22:23:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://trf.mncable.net/> from <GET http://trf.mncable.net/>
2018-10-23 22:23:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://erppd.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cmec.coop/> (referer: None)
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sciremc.com/> (referer: None)
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.mitchellcity.net/robots.txt/> from <GET https://www.mitchellcity.net/robots.txt>
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.sweci.com/robots.txt> (referer: None)
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (401) <GET https://cas.sharepoint.illinoisstate.edu/robots.txt> (referer: None)
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.mitchellcity.net/robots.txt/> from <GET http://www.mitchellcity.net/robots.txt/>
2018-10-23 22:23:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cmec.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.sciremc.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.sweci.com/Home.aspx> from <GET http://www.sweci.com>
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.mitchellcity.net/robots.txt/Default.aspx> from <GET https://www.mitchellcity.net/robots.txt/>
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (401) <GET https://cas.sharepoint.illinoisstate.edu> (referer: None)
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mitchellcity.net/robots.txt/Default.aspx> (referer: None)
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cwremc.com/robots.txt> (referer: None)
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ppec.coop/robots.txt> (referer: None)
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://trf.mncable.net/> (referer: None)
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://cityofmadisonsd.com/robots.txt> from <GET http://www.cityofmadisonsd.com/robots.txt>
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.mitchellcity.net/> from <GET http://www.mitchellcity.net>
2018-10-23 22:23:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <401 https://cas.sharepoint.illinoisstate.edu>: HTTP status code is not handled or not allowed
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.sweci.com/Home.aspx> (referer: None)
2018-10-23 22:23:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://trf.mncable.net/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://media.wix.com/robots.txt> (referer: None)
2018-10-23 22:23:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.sweci.com/Home.aspx> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-Home.aspx.html'
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://media.wix.com> (referer: None)
2018-10-23 22:23:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://media.wix.com>: HTTP status code is not handled or not allowed
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.dce.coop/robots.txt> (referer: None)
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.dce.coop> (referer: None)
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.aztecnm.gov/robots.txt> (referer: None)
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mitchellcity.net/> (referer: None)
2018-10-23 22:23:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dce.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.dce.coop.html'
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://vtes.vt.edu/robots.txt> from <GET http://www.vtes.vt.edu/robots.txt>
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.aztecnm.gov> (referer: None)
2018-10-23 22:23:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.mitchellcity.net/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.hfrecc.com/robots.txt> (failed 1 times): DNS lookup failed: no results for hostname lookup: www.hfrecc.com.
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.hfrecc.com/robots.txt> (failed 2 times): DNS lookup failed: no results for hostname lookup: www.hfrecc.com.
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.hfrecc.com/robots.txt> (failed 3 times): DNS lookup failed: no results for hostname lookup: www.hfrecc.com.
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.hfrecc.com/robots.txt>: DNS lookup failed: no results for hostname lookup: www.hfrecc.com.
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.hfrecc.com.
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.hfrecc.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: www.hfrecc.com.
2018-10-23 22:23:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.aztecnm.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.aztecnm.gov.html'
2018-10-23 22:23:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.amlegal.com/robots.txt> (referer: None)
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.hfrecc.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: www.hfrecc.com.
2018-10-23 22:23:56 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://www.hfrecc.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: www.hfrecc.com.
2018-10-23 22:23:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://vtes.vt.edu/content/dam/vtes_vt_edu/robots.txt> from <GET https://vtes.vt.edu/robots.txt>
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cityofmadisonsd.com/robots.txt> (referer: None)
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://vtes.vt.edu/content/dam/vtes_vt_edu/robots.txt> (referer: None)
2018-10-23 22:23:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://perennialpower.com/robots.txt> from <GET http://www.perennialpower.com/robots.txt>
2018-10-23 22:23:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://cityofmadisonsd.com/> from <GET http://www.cityofmadisonsd.com>
2018-10-23 22:23:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.hfrecc.com>
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.hfrecc.com.
2018-10-23 22:23:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://vtes.vt.edu/> from <GET http://www.vtes.vt.edu>
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ucnsb.org/robots.txt> (referer: None)
2018-10-23 22:23:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://vtes.vt.edu/content/dam/vtes_vt_edu/robots.txt> from <GET https://vtes.vt.edu/robots.txt>
2018-10-23 22:23:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://ucnsb.org/> from <GET http://ucnsb.org>
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://vtes.vt.edu/content/dam/vtes_vt_edu/robots.txt> (referer: None)
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://vtes.vt.edu/> (referer: None)
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://z2.franklinlegal.net/robots.txt> (referer: None)
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://perennialpower.com/robots.txt> (referer: None)
2018-10-23 22:23:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.ucnsb.org/> from <GET https://ucnsb.org/>
2018-10-23 22:23:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://perennialpower.com/> from <GET http://www.perennialpower.com>
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://z2.franklinlegal.net> (referer: None)
2018-10-23 22:23:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vtes.vt.edu/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://perennialpower.com/robots.txt> (referer: None)
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://perennialpower.com/> (referer: None)
2018-10-23 22:23:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://z2.franklinlegal.net>: HTTP status code is not handled or not allowed
2018-10-23 22:23:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://ppec.coop/> from <GET http://www.ppec.coop>
2018-10-23 22:23:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://perennialpower.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ucnsb.org/robots.txt> (referer: None)
2018-10-23 22:23:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://energy.gov/robots.txt> from <GET http://energy.gov/robots.txt>
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ucnsb.org/> (referer: None)
2018-10-23 22:23:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.energy.gov/robots.txt> from <GET https://energy.gov/robots.txt>
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cityofmadisonsd.com/robots.txt> (referer: None)
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.nvenergy.com/robots.txt> (referer: None)
2018-10-23 22:23:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ucnsb.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cwremc.com> (referer: None)
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.nvenergy.com> (referer: None)
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.energy.gov/robots.txt> (referer: None)
2018-10-23 22:23:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cwremc.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cwremc.com.html'
2018-10-23 22:23:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.newhamptonia.com/robots.txt> (referer: None)
2018-10-23 22:23:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://energy.gov/> from <GET http://energy.gov>
2018-10-23 22:23:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nvenergy.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.nvenergy.com.html'
2018-10-23 22:23:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.newhamptonia.com> (referer: None)
2018-10-23 22:23:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.energy.gov/> from <GET https://energy.gov/>
2018-10-23 22:23:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.aswater.com/robots.txt> (referer: None)
2018-10-23 22:23:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.newhamptonia.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.newhamptonia.com.html'
2018-10-23 22:23:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.energy.gov/robots.txt> (referer: None)
2018-10-23 22:23:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.connexusenergy.com/robots.txt> (referer: None)
2018-10-23 22:23:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.riogrande.coop/robots.txt> from <GET http://www.riogrande.coop/robots.txt>
2018-10-23 22:23:58 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.riogrande.coop/robots.txt> (referer: None)
2018-10-23 22:23:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.riogrande.coop/> from <GET http://www.riogrande.coop>
2018-10-23 22:23:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cityofmadisonsd.com/> (referer: None)
2018-10-23 22:23:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.riogrande.coop/> (referer: None)
2018-10-23 22:23:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.connexusenergy.com> (referer: None)
2018-10-23 22:23:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://cityofmadisonsd.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.riogrande.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.connexusenergy.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.connexusenergy.com.html'
2018-10-23 22:23:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ppec.coop/robots.txt> (referer: None)
2018-10-23 22:23:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.pkmcoop.com/robots.txt> (referer: None)
2018-10-23 22:23:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.guc.com/robots.txt> from <GET http://www.guc.com/robots.txt>
2018-10-23 22:23:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.aswater.com> (referer: None)
2018-10-23 22:23:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ppec.coop/> (referer: None)
2018-10-23 22:23:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.aswater.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.aswater.com.html'
2018-10-23 22:23:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.fcgov.com/robots.txt> from <GET http://www.fcgov.com/robots.txt>
2018-10-23 22:23:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ppec.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.guc.com/robots.txt> (referer: None)
2018-10-23 22:23:59 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://new.washingtoncity.org/robots.txt> (referer: None)
2018-10-23 22:23:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.guc.com/> from <GET http://www.guc.com>
2018-10-23 22:23:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.amlegal.com> (referer: None)
2018-10-23 22:23:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://cloud.washingtoncity.org/> from <GET http://new.washingtoncity.org>
2018-10-23 22:23:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.amlegal.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.amlegal.com.html'
2018-10-23 22:23:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.pkmcoop.com> (referer: None)
2018-10-23 22:23:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.guc.com/> (referer: None)
2018-10-23 22:23:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.pkmcoop.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.pkmcoop.com.html'
2018-10-23 22:23:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.fcgov.com/robots.txt> (referer: None)
2018-10-23 22:23:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.guc.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:23:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.orbgdpu.com/robots.txt> (referer: None)
2018-10-23 22:24:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.fcgov.com/> from <GET http://www.fcgov.com>
2018-10-23 22:24:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lebanonmissouri.org/robots.txt> (referer: None)
2018-10-23 22:24:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.orbgdpu.com> (referer: None)
2018-10-23 22:24:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.cityofgreendale.net/robots.txt> from <GET http://cityofgreendale.net/robots.txt>
2018-10-23 22:24:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.orbgdpu.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.orbgdpu.com.html'
2018-10-23 22:24:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.naelectric.com/robots.txt> (referer: None)
2018-10-23 22:24:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.fcgov.com/> (referer: None)
2018-10-23 22:24:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.naelectric.com> (referer: None)
2018-10-23 22:24:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofgreendale.net/robots.txt> (referer: None)
2018-10-23 22:24:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.fcgov.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.naelectric.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.naelectric.com.html'
2018-10-23 22:24:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://washingtoncity.org/404/index.php?search=robots.txt> from <GET http://cloud.washingtoncity.org/robots.txt>
2018-10-23 22:24:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.cityofgreendale.net/> from <GET http://cityofgreendale.net>
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.flatheadelectric.com/robots.txt> (referer: None)
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://missoulaelectric.com/robots.txt> (referer: None)
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.oakdalerec.com/robots.txt> (referer: None)
2018-10-23 22:24:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.flatheadelectric.com/> from <GET http://www.flatheadelectric.com>
2018-10-23 22:24:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.nypa.gov/robots.txt> from <GET http://www.nypa.gov/robots.txt>
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofgreendale.net/robots.txt> (referer: None)
2018-10-23 22:24:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.nypa.gov> from <GET https://www.nypa.gov/robots.txt>
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.oakdalerec.com> (referer: None)
2018-10-23 22:24:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.oakdalerec.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.oakdalerec.com.html'
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lebanonmissouri.org> (referer: None)
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofgreendale.net/> (referer: None)
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.natchitochesla.gov/robots.txt> (referer: None)
2018-10-23 22:24:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.lebanonmissouri.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.lebanonmissouri.org.html'
2018-10-23 22:24:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cityofgreendale.net/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.nypa.gov> (referer: None)
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.xcelenergy.com/robots.txt> (referer: None)
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.flatheadelectric.com/> (referer: None)
2018-10-23 22:24:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.nypa.gov/> from <GET http://www.nypa.gov>
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.natchitochesla.gov> (referer: None)
2018-10-23 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.xcelenergy.com> (referer: None)
2018-10-23 22:24:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.flatheadelectric.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.natchitochesla.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.natchitochesla.gov.html'
2018-10-23 22:24:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xcelenergy.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.xcelenergy.com.html'
2018-10-23 22:24:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.farmersrecc.com/robots.txt> from <GET http://www.farmersrecc.com/robots.txt>
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.nypa.gov/> (referer: None)
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://psc.ky.gov/robots.txt> (referer: None)
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.farmersrecc.com/robots.txt> (referer: None)
2018-10-23 22:24:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://psc.ky.gov:443/> from <GET http://psc.ky.gov>
2018-10-23 22:24:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nypa.gov/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.farmersrecc.com/> from <GET http://www.farmersrecc.com>
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.alta-tec.net/robots.txt> (referer: None)
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.psoklahoma.com/robots.txt> (referer: None)
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.alta-tec.net> (referer: None)
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://psc.ky.gov:443/robots.txt> (referer: None)
2018-10-23 22:24:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.alta-tec.net> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.alta-tec.net.html'
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.psoklahoma.com> (referer: None)
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.energy.gov/> (referer: None)
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.clintonutilities.com/robots.txt> (referer: None)
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jasperremc.com/robots.txt> (referer: None)
2018-10-23 22:24:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.psoklahoma.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.psoklahoma.com.html'
2018-10-23 22:24:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://missoulaelectric.com/> from <GET http://missoulaelectric.com>
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://psc.ky.gov:443/> (referer: None)
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.clintonutilities.com> (referer: None)
2018-10-23 22:24:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.energy.gov/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://psc.ky.gov:443/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.clintonutilities.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.clintonutilities.com.html'
2018-10-23 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.plummerid.govoffice3.com/robots.txt> (referer: None) ['partial']
2018-10-23 22:24:02 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://www.plummerid.govoffice3.com>
2018-10-23 22:24:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.pge.com/robots.txt> from <GET http://www.pge.com/robots.txt>
2018-10-23 22:24:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.farmersrecc.com/> (referer: None)
2018-10-23 22:24:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.farmersrecc.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:03 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://washingtoncity.org/404/index.php?search=robots.txt> (referer: None)
2018-10-23 22:24:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jasperremc.com> (referer: None)
2018-10-23 22:24:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jasperremc.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.jasperremc.com.html'
2018-10-23 22:24:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pge.com/robots.txt> (referer: None)
2018-10-23 22:24:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.pge.com/> from <GET http://www.pge.com>
2018-10-23 22:24:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://washingtoncity.org/tex/> from <GET http://cloud.washingtoncity.org/>
2018-10-23 22:24:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.appalachianpower.com/robots.txt> (referer: None)
2018-10-23 22:24:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofchewelah.org/robots.txt> (referer: None)
2018-10-23 22:24:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.uppco.com/robots.txt> from <GET http://www.uppco.com/robots.txt>
2018-10-23 22:24:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.osceolaelectric.com/robots.txt> (referer: None)
2018-10-23 22:24:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.appalachianpower.com> (referer: None)
2018-10-23 22:24:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.appalachianpower.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.appalachianpower.com.html'
2018-10-23 22:24:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://washingtoncity.org/404/index.php?search=robots.txt> from <GET https://washingtoncity.org/robots.txt>
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ci.mora.mn.us/robots.txt> (referer: None) ['partial']
2018-10-23 22:24:04 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://www.ci.mora.mn.us>
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pge.com/> (referer: None)
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.uppco.com/robots.txt> (referer: None)
2018-10-23 22:24:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pge.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.lub.org/robots.txt> (referer: None)
2018-10-23 22:24:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.uppco.com/> from <GET http://www.uppco.com>
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.skrecc.com/robots.txt> (referer: None)
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.skrecc.com> (referer: None)
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lub.org> (referer: None)
2018-10-23 22:24:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.skrecc.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.skrecc.com.html'
2018-10-23 22:24:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.lub.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.lub.org.html'
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.greenmountainpower.com/robots.txt> (referer: None)
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.csu.org/robots.txt> (referer: None)
2018-10-23 22:24:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.greenmountainpower.com/> from <GET http://www.greenmountainpower.com>
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofchewelah.org> (referer: None)
2018-10-23 22:24:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.csu.org/Pages/default.aspx> from <GET https://www.csu.org>
2018-10-23 22:24:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cityofchewelah.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cityofchewelah.org.html'
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.uppco.com/> (referer: None)
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.screc.com/robots.txt> (referer: None)
2018-10-23 22:24:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://greenmountainpower.com/> from <GET https://www.greenmountainpower.com/>
2018-10-23 22:24:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.uppco.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:04 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.ccelectric.org/robots.txt> (referer: None)
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ccelectric.org> (referer: None)
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://missoulaelectric.com/> (referer: None)
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.csu.org/Pages/default.aspx> (referer: None)
2018-10-23 22:24:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.ccelectric.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.ccelectric.org.html'
2018-10-23 22:24:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://fpb.cc/robots.txt> from <GET http://fpb.cc/robots.txt>
2018-10-23 22:24:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://missoulaelectric.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csu.org/Pages/default.aspx> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-default.aspx.html'
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.screc.com> (referer: None)
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://washingtoncity.org/404/index.php?search=robots.txt> (referer: None)
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://greenmountainpower.com/robots.txt> (referer: None)
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://greenmountainpower.com/> (referer: None)
2018-10-23 22:24:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.screc.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.screc.com.html'
2018-10-23 22:24:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://greenmountainpower.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.kec-sd.coop/robots.txt> (referer: None)
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.mifflinburgborough.org/robots.txt> (referer: None)
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://fpb.cc/robots.txt> (referer: None)
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.jacksonohio.us/robots.txt> (referer: None)
2018-10-23 22:24:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://fpb.cc/> from <GET http://fpb.cc>
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.sie.coop/robots.txt> (referer: None)
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://washingtoncity.org/tex/> (referer: None)
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jacksonohio.us> (referer: None)
2018-10-23 22:24:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://washingtoncity.org/tex/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://fpb.cc/> (referer: None)
2018-10-23 22:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lagrangeremc.com/robots.txt> (referer: None)
2018-10-23 22:24:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jacksonohio.us> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.jacksonohio.us.html'
2018-10-23 22:24:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://fpb.cc/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.selma.govoffice2.com/robots.txt> (referer: None) ['partial']
2018-10-23 22:24:06 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://www.selma.govoffice2.com>
2018-10-23 22:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.sie.coop> (referer: None)
2018-10-23 22:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ssvec.org/robots.txt> (referer: None)
2018-10-23 22:24:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.sie.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.sie.coop.html'
2018-10-23 22:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lagrangeremc.com> (referer: None)
2018-10-23 22:24:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.lagrangeremc.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.lagrangeremc.com.html'
2018-10-23 22:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.townofblackstoneva.com/robots.txt> (referer: None)
2018-10-23 22:24:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.townofblackstoneva.com/> from <GET http://www.townofblackstoneva.com>
2018-10-23 22:24:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.cityofiola.com/robots.txt> from <GET http://www.cityofiola.com/robots.txt>
2018-10-23 22:24:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://mifflinburgborough.org/> from <GET http://www.mifflinburgborough.org>
2018-10-23 22:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.mlandp.com/robots.txt> (referer: None)
2018-10-23 22:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.gardnerkansas.gov/robots.txt> (referer: None)
2018-10-23 22:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mifflinburgborough.org/robots.txt> (referer: None)
2018-10-23 22:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cityofiola.com/robots.txt> (referer: None)
2018-10-23 22:24:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.cityofiola.com/> from <GET http://www.cityofiola.com>
2018-10-23 22:24:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.nespower.com/robots.txt> from <GET http://www.nespower.com/robots.txt>
2018-10-23 22:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ssvec.org> (referer: None)
2018-10-23 22:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.mlandp.com> (referer: None)
2018-10-23 22:24:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.ssvec.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.ssvec.org.html'
2018-10-23 22:24:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.mlandp.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.mlandp.com.html'
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.townofblackstoneva.com/> (referer: None)
2018-10-23 22:24:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.townofblackstoneva.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.gardnerkansas.gov> (referer: None)
2018-10-23 22:24:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://dawsonpower.com/robots.txt> from <GET http://www.dawsonpower.com/robots.txt>
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.nespower.com/robots.txt> (referer: None)
2018-10-23 22:24:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.nespower.com/> from <GET http://www.nespower.com>
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://dawsonpower.com/robots.txt> (referer: None)
2018-10-23 22:24:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gardnerkansas.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.gardnerkansas.gov.html'
2018-10-23 22:24:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://dawsonpower.com/> from <GET http://www.dawsonpower.com>
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://dawsonpower.com/robots.txt> (referer: None)
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cityofiola.com/> (referer: None)
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://dawsonpower.com/> (referer: None)
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.nespower.com/> (referer: None)
2018-10-23 22:24:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cityofiola.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://dawsonpower.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nespower.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://harris.lagrange-ga.org/robots.txt> (referer: None)
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.cityofgeneseo.com/robots.txt> (referer: None)
2018-10-23 22:24:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://harris.lagrange-ga.org/loginbyemail.asp> from <GET https://harris.lagrange-ga.org>
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.osceolaelectric.com> (referer: None)
2018-10-23 22:24:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.osceolaelectric.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.osceolaelectric.com.html'
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofgeneseo.com> (referer: None)
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.freeportelectric.com/robots.txt> (referer: None)
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mifflinburgborough.org/> (referer: None)
2018-10-23 22:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://harris.lagrange-ga.org/loginbyemail.asp> (referer: None)
2018-10-23 22:24:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cityofgeneseo.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cityofgeneseo.com.html'
2018-10-23 22:24:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mifflinburgborough.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://harris.lagrange-ga.org/loginbyemail.asp> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-loginbyemail.asp.html'
2018-10-23 22:24:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://meadvillemo.weebly.com> from <GET http://www.meadvillemo.com/robots.txt>
2018-10-23 22:24:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://meadvillemo.weebly.com/> from <GET http://meadvillemo.weebly.com>
2018-10-23 22:24:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ci.waseca.mn.us/robots.txt> (referer: None)
2018-10-23 22:24:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://meadvillemo.weebly.com/> (referer: None)
2018-10-23 22:24:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://meadvillemo.weebly.com> from <GET http://www.meadvillemo.com>
2018-10-23 22:24:08 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.dleg.state.mi.us/robots.txt> (referer: None)
2018-10-23 22:24:08 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.dleg.state.mi.us> (referer: None)
2018-10-23 22:24:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://meadvillemo.weebly.com/robots.txt> from <GET http://meadvillemo.weebly.com/robots.txt>
2018-10-23 22:24:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.dleg.state.mi.us>: HTTP status code is not handled or not allowed
2018-10-23 22:24:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.freeportelectric.com> (referer: None)
2018-10-23 22:24:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://meadvillemo.weebly.com/robots.txt> (referer: None)
2018-10-23 22:24:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.kec-sd.coop> (referer: None)
2018-10-23 22:24:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.freeportelectric.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.freeportelectric.com.html'
2018-10-23 22:24:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://ci.waseca.mn.us/> from <GET http://www.ci.waseca.mn.us>
2018-10-23 22:24:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://meadvillemo.weebly.com/> from <GET http://meadvillemo.weebly.com>
2018-10-23 22:24:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.georgetownma.gov/robots.txt> from <GET http://www.georgetownma.gov/robots.txt>
2018-10-23 22:24:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.kec-sd.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.kec-sd.coop.html'
2018-10-23 22:24:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.georgetownma.gov/robots.txt> (referer: None)
2018-10-23 22:24:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.georgetownma.gov/> from <GET http://www.georgetownma.gov>
2018-10-23 22:24:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://meadvillemo.weebly.com/> (referer: None)
2018-10-23 22:24:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.georgetownma.gov/> (referer: None)
2018-10-23 22:24:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://meadvillemo.weebly.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.georgetownma.gov/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cimarronks.org/robots.txt> (referer: None)
2018-10-23 22:24:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ci.waseca.mn.us/robots.txt> (referer: None)
2018-10-23 22:24:09 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://psc.state.wy.us/robots.txt> (referer: None)
2018-10-23 22:24:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.villageofwinnetka.org/robots.txt> (referer: None)
2018-10-23 22:24:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://psc.state.wy.us> (referer: None)
2018-10-23 22:24:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://psc.state.wy.us> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-psc.state.wy.us.html'
2018-10-23 22:24:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.villageofwinnetka.org/> from <GET http://www.villageofwinnetka.org>
2018-10-23 22:24:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://cimarronks.org/> from <GET http://www.cimarronks.org>
2018-10-23 22:24:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://missionvalleypower.org/robots.txt> (referer: None)
2018-10-23 22:24:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.santeecooper.com/404.aspx> from <GET https://www.santeecooper.com/robots.txt>
2018-10-23 22:24:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ci.waseca.mn.us/> (referer: None)
2018-10-23 22:24:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.santeecooper.com/404.aspx> (referer: None)
2018-10-23 22:24:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ci.waseca.mn.us/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.santeecooper.com> (referer: None)
2018-10-23 22:24:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.santeecooper.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.santeecooper.com.html'
2018-10-23 22:24:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://cimarronks.org/robots.txt> (referer: None)
2018-10-23 22:24:10 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://cnmec.org/robots.txt> (referer: None)
2018-10-23 22:24:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.villageofwinnetka.org/> (referer: None)
2018-10-23 22:24:11 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.ozarkelectric.com/robots.txt> (referer: None)
2018-10-23 22:24:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://cnmec.org> (referer: None)
2018-10-23 22:24:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.villageofwinnetka.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://ure.com/robots.txt> from <GET http://ure.com/robots.txt>
2018-10-23 22:24:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://cnmec.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-cnmec.org.html'
2018-10-23 22:24:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.vermillion.us/robots.txt> from <GET http://www.vermillion.us/robots.txt>
2018-10-23 22:24:11 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.northfield-vt.gov/robots.txt> (referer: None)
2018-10-23 22:24:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ure.com/robots.txt> (referer: None)
2018-10-23 22:24:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.northfield-vt.gov> (referer: None)
2018-10-23 22:24:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://ure.com/> from <GET http://ure.com>
2018-10-23 22:24:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.vermillion.us/robots.txt> (referer: None)
2018-10-23 22:24:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.northfield-vt.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.northfield-vt.gov.html'
2018-10-23 22:24:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.vermillion.us/> from <GET http://www.vermillion.us>
2018-10-23 22:24:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ure.com/> (referer: None)
2018-10-23 22:24:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://cimarronks.org/> (referer: None)
2018-10-23 22:24:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ozarkelectric.com> (referer: None)
2018-10-23 22:24:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ure.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://cimarronks.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.ozarkelectric.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.ozarkelectric.com.html'
2018-10-23 22:24:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.pvrea.com/robots.txt> from <GET http://www.pvrea.com/robots.txt>
2018-10-23 22:24:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pvrea.com/robots.txt> (referer: None)
2018-10-23 22:24:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.pvrea.com/> from <GET http://www.pvrea.com>
2018-10-23 22:24:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.frenchbroademc.com/robots.txt> from <GET http://www.frenchbroademc.com/robots.txt>
2018-10-23 22:24:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.vermillion.us/> (referer: None)
2018-10-23 22:24:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.vermillion.us/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pvrea.com/> (referer: None)
2018-10-23 22:24:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.frenchbroademc.com/robots.txt> (referer: None)
2018-10-23 22:24:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pvrea.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.frenchbroademc.com/> from <GET http://www.frenchbroademc.com>
2018-10-23 22:24:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.northwesternenergy.com/robots.txt> (referer: None)
2018-10-23 22:24:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.frenchbroademc.com/> (referer: None)
2018-10-23 22:24:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.waltonemc.com/robots.txt> from <GET http://www.waltonemc.com/robots.txt>
2018-10-23 22:24:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.hudsonlight.com/robots.txt> (referer: None)
2018-10-23 22:24:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.frenchbroademc.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://cdelightband.comrobots.txt> from <GET http://www.clarksvillede.com/robots.txt>
2018-10-23 22:24:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://cdelightband.comrobots.txt> (failed 1 times): DNS lookup failed: no results for hostname lookup: cdelightband.comrobots.txt.
2018-10-23 22:24:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://cdelightband.comrobots.txt> (failed 2 times): DNS lookup failed: no results for hostname lookup: cdelightband.comrobots.txt.
2018-10-23 22:24:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://cdelightband.comrobots.txt> (failed 3 times): DNS lookup failed: no results for hostname lookup: cdelightband.comrobots.txt.
2018-10-23 22:24:13 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.clarksvillede.com/robots.txt>: DNS lookup failed: no results for hostname lookup: cdelightband.comrobots.txt.
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: cdelightband.comrobots.txt.
2018-10-23 22:24:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://cdelightband.com> from <GET http://www.clarksvillede.com>
2018-10-23 22:24:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.northwesternenergy.com> (referer: None)
2018-10-23 22:24:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.northwesternenergy.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.northwesternenergy.com.html'
2018-10-23 22:24:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://nlrelectric.com/robots.txt> (referer: None)
2018-10-23 22:24:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.ctec.coop/robots.txt> from <GET http://www.ctec.coop/robots.txt>
2018-10-23 22:24:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ctec.coop/robots.txt> (referer: None)
2018-10-23 22:24:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.ctec.coop/> from <GET http://www.ctec.coop>
2018-10-23 22:24:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://missionvalleypower.org/> from <GET http://missionvalleypower.org>
2018-10-23 22:24:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cdelightband.com/robots.txt> (referer: None)
2018-10-23 22:24:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cdelightband.com> (referer: None)
2018-10-23 22:24:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ctec.coop/> (referer: None)
2018-10-23 22:24:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.maconelectric.com/robots.txt> (referer: None)
2018-10-23 22:24:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://cdelightband.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-cdelightband.com.html'
2018-10-23 22:24:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ctec.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.holycross.com/robots.txt> from <GET http://www.holycross.com/robots.txt>
2018-10-23 22:24:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.maconelectric.com/> from <GET http://www.maconelectric.com>
2018-10-23 22:24:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.maconelectric.com/> (referer: None)
2018-10-23 22:24:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.holycross.com/robots.txt> (referer: None)
2018-10-23 22:24:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.holycross.com/> from <GET http://www.holycross.com>
2018-10-23 22:24:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.maconelectric.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.holycross.com/> (referer: None)
2018-10-23 22:24:15 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.nicholasville.org/robots.txt> (referer: None)
2018-10-23 22:24:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.holycross.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.lpea.com/robots.txt> from <GET http://www.lpea.com/robots.txt>
2018-10-23 22:24:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nicholasville.org> (referer: None)
2018-10-23 22:24:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.lpea.com/robots.txt> (referer: None)
2018-10-23 22:24:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.nicholasville.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.nicholasville.org.html'
2018-10-23 22:24:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.lpea.com/> from <GET http://www.lpea.com>
2018-10-23 22:24:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://nlrelectric.com> (referer: None)
2018-10-23 22:24:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.concordma.gov/robots.txt> (referer: None)
2018-10-23 22:24:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nlrelectric.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-nlrelectric.com.html'
2018-10-23 22:24:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.lpea.com/> (referer: None)
2018-10-23 22:24:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofwatervilleks.org/robots.txt> (referer: None)
2018-10-23 22:24:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.lpea.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://cityofwatervilleks.org/> from <GET http://www.cityofwatervilleks.org>
2018-10-23 22:24:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://cityofwatervilleks.org/robots.txt> (referer: None)
2018-10-23 22:24:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.concordma.gov> (referer: None)
2018-10-23 22:24:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://missionvalleypower.org/> (referer: None)
2018-10-23 22:24:16 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.cvea.org/robots.txt> (referer: None)
2018-10-23 22:24:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.concordma.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.concordma.gov.html'
2018-10-23 22:24:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://missionvalleypower.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.kcpl.com/robots.txt> from <GET http://www.kcpl.com/robots.txt>
2018-10-23 22:24:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://medinaec.org/robots.txt> from <GET http://medinaec.org/robots.txt>
2018-10-23 22:24:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://cityofwatervilleks.org/> (referer: None)
2018-10-23 22:24:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cvea.org> (referer: None)
2018-10-23 22:24:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://cityofwatervilleks.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cvea.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cvea.org.html'
2018-10-23 22:24:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://medinaec.org/robots.txt> (referer: None)
2018-10-23 22:24:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.clearwaterpower.com/robots.txt> (referer: None)
2018-10-23 22:24:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://medinaec.org/> from <GET http://medinaec.org>
2018-10-23 22:24:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.kcpl.com/robots.txt> (referer: None)
2018-10-23 22:24:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.kcpl.com/> from <GET http://www.kcpl.com>
2018-10-23 22:24:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.aptalaska.com/robots.txt> from <GET http://www.aptalaska.com/robots.txt>
2018-10-23 22:24:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.clearwaterpower.com> (referer: None)
2018-10-23 22:24:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.kcpl.com/> (referer: None)
2018-10-23 22:24:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://medinaec.org/> (referer: None)
2018-10-23 22:24:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.clearwaterpower.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.clearwaterpower.com.html'
2018-10-23 22:24:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.kcpl.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://medinaec.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.craigheadelectric.coop/robots.txt> from <GET http://www.craigheadelectric.coop/robots.txt>
2018-10-23 22:24:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.hudsonlight.com> (referer: None)
2018-10-23 22:24:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.vermontelectric.coop/robots.txt> from <GET http://www.vermontelectric.coop/robots.txt>
2018-10-23 22:24:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.hudsonlight.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.hudsonlight.com.html'
2018-10-23 22:24:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.aptalaska.com/robots.txt> (referer: None)
2018-10-23 22:24:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.craigheadelectric.coop/robots.txt> (referer: None)
2018-10-23 22:24:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.craigheadelectric.coop/> from <GET http://www.craigheadelectric.coop>
2018-10-23 22:24:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.aptalaska.com/> from <GET http://www.aptalaska.com>
2018-10-23 22:24:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.craigheadelectric.coop/> (referer: None)
2018-10-23 22:24:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.danville-va.gov/robots.txt> (referer: None)
2018-10-23 22:24:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.craigheadelectric.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:18 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.vermontelectric.coop/robots.txt> (referer: None)
2018-10-23 22:24:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.aptalaska.com/> (referer: None)
2018-10-23 22:24:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://billing.cecpowerup.com/oscp/robots.txt> from <GET http://chickasaw.coop/robots.txt>
2018-10-23 22:24:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.aptalaska.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.vermontelectric.coop/> from <GET http://www.vermontelectric.coop>
2018-10-23 22:24:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.waltonemc.com/robots.txt> (referer: None)
2018-10-23 22:24:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.waltonemc.com/> from <GET http://www.waltonemc.com>
2018-10-23 22:24:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.hope-wl.com/robots.txt> from <GET http://www.hope-wl.com/robots.txt>
2018-10-23 22:24:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.cityofsheboyganfalls.com/robots.txt> from <GET http://www.cityofsheboyganfalls.com/robots.txt>
2018-10-23 22:24:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.hope-wl.com/notfound.aspx> from <GET https://www.hope-wl.com/robots.txt>
2018-10-23 22:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.danville-va.gov> (referer: None)
2018-10-23 22:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.vermontelectric.coop/> (referer: None)
2018-10-23 22:24:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.danville-va.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.danville-va.gov.html'
2018-10-23 22:24:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.vermontelectric.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.hope-wl.com/notfound.aspx> (referer: None)
2018-10-23 22:24:19 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://billing.cecpowerup.com/oscp/robots.txt> (referer: None)
2018-10-23 22:24:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.hope-wl.com/> from <GET http://www.hope-wl.com>
2018-10-23 22:24:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://billing.cecpowerup.com/oscp/> from <GET http://chickasaw.coop>
2018-10-23 22:24:19 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://billing.cecpowerup.com/robots.txt> (referer: None)
2018-10-23 22:24:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET http://cbec.cc/robots.txt> from <GET http://www.cbec.cc/robots.txt>
2018-10-23 22:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.greenwoodcpw.com/robots.txt> (referer: None)
2018-10-23 22:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cityofsheboyganfalls.com/robots.txt> (referer: None)
2018-10-23 22:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.hope-wl.com/> (referer: None)
2018-10-23 22:24:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://cbec.cc/robots.txt> from <GET http://cbec.cc/robots.txt>
2018-10-23 22:24:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.hope-wl.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://billing.cecpowerup.com/oscp/BrowserNotSupported.aspx> from <GET https://billing.cecpowerup.com/oscp/>
2018-10-23 22:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://billing.cecpowerup.com/oscp/BrowserNotSupported.aspx> (referer: None)
2018-10-23 22:24:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://billing.cecpowerup.com/oscp/BrowserNotSupported.aspx> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-BrowserNotSupported.aspx.html'
2018-10-23 22:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.greenwoodcpw.com> (referer: None)
2018-10-23 22:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cbec.cc/robots.txt> (referer: None)
2018-10-23 22:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.pella-cea.org/robots.txt> (referer: None)
2018-10-23 22:24:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.greenwoodcpw.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.greenwoodcpw.com.html'
2018-10-23 22:24:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET http://cbec.cc/> from <GET http://www.cbec.cc>
2018-10-23 22:24:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.cityofsheboyganfalls.com/> from <GET http://www.cityofsheboyganfalls.com>
2018-10-23 22:24:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://cbec.cc/robots.txt> from <GET http://cbec.cc/robots.txt>
2018-10-23 22:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fcec.coop/robots.txt> (referer: None)
2018-10-23 22:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cbec.cc/robots.txt> (referer: None)
2018-10-23 22:24:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://cbec.cc/> from <GET http://cbec.cc/>
2018-10-23 22:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.pella-cea.org> (referer: None)
2018-10-23 22:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.owenelectric.com/robots.txt> (referer: None)
2018-10-23 22:24:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.pella-cea.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.pella-cea.org.html'
2018-10-23 22:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.waltonemc.com/> (referer: None)
2018-10-23 22:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fcec.coop> (referer: None)
2018-10-23 22:24:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.waltonemc.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.itasca-mantrap.com/robots.txt> (referer: None)
2018-10-23 22:24:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://fcec.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-fcec.coop.html'
2018-10-23 22:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cbec.cc/> (referer: None)
2018-10-23 22:24:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.xcelenergy.com/> from <GET http://www.xcelenergy.com>
2018-10-23 22:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://rooseveltppd.com/robots.txt> (referer: None)
2018-10-23 22:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.owenelectric.com> (referer: None)
2018-10-23 22:24:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://cbec.cc/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.owenelectric.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.owenelectric.com.html'
2018-10-23 22:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.itasca-mantrap.com> (referer: None)
2018-10-23 22:24:21 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.cmpco.com/robots.txt> (referer: None)
2018-10-23 22:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://rooseveltppd.com> (referer: None)
2018-10-23 22:24:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.itasca-mantrap.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.itasca-mantrap.com.html'
2018-10-23 22:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cmpco.com> (referer: None)
2018-10-23 22:24:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://rooseveltppd.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-rooseveltppd.com.html'
2018-10-23 22:24:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cmpco.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cmpco.com.html'
2018-10-23 22:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cityofsheboyganfalls.com/> (referer: None)
2018-10-23 22:24:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cityofsheboyganfalls.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bpw.zeeland.mi.us/robots.txt> (referer: None)
2018-10-23 22:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.aikenco-op.org/robots.txt> (referer: None)
2018-10-23 22:24:22 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://valleycity.govoffice.com/robots.txt> (referer: None)
2018-10-23 22:24:22 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://valleycity.govoffice.com> (referer: None)
2018-10-23 22:24:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://valleycity.govoffice.com>: HTTP status code is not handled or not allowed
2018-10-23 22:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.gibsonemc.com/robots.txt> (referer: None)
2018-10-23 22:24:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://zeelandbpw.com/> from <GET http://www.bpw.zeeland.mi.us>
2018-10-23 22:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bensonmn.org/robots.txt> (referer: None) ['partial']
2018-10-23 22:24:22 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://www.bensonmn.org>
2018-10-23 22:24:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.aikenco-op.org> (referer: None)
2018-10-23 22:24:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.aikenco-op.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.aikenco-op.org.html'
2018-10-23 22:24:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.wolfeboronh.us/robots.txt> from <GET http://www.wolfeboronh.us/robots.txt>
2018-10-23 22:24:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.wolfeboronh.us/robots.txt> (referer: None)
2018-10-23 22:24:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.wolfeboronh.us/> from <GET http://www.wolfeboronh.us>
2018-10-23 22:24:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.gibsonemc.com> (referer: None)
2018-10-23 22:24:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://zeelandbpw.com/robots.txt> (referer: None)
2018-10-23 22:24:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.wolfeboronh.us/> (referer: None)
2018-10-23 22:24:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gibsonemc.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.gibsonemc.com.html'
2018-10-23 22:24:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.wolfeboronh.us/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://zeelandbpw.com/> (referer: None)
2018-10-23 22:24:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zeelandbpw.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.vinelandcity.org/robots.txt> (referer: None)
2018-10-23 22:24:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.vinelandcity.org> (referer: None)
2018-10-23 22:24:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.vinelandcity.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.vinelandcity.org.html'
2018-10-23 22:24:37 [scrapy.extensions.logstats] INFO: Crawled 515 pages (at 515 pages/min), scraped 0 items (at 0 items/min)
2018-10-23 22:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.heartlandpower.com/robots.txt> (referer: None)
2018-10-23 22:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.wyan.org/robots.txt> (referer: None)
2018-10-23 22:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.heartlandpower.com> (referer: None)
2018-10-23 22:24:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://erppd.com/> from <GET http://erppd.com>
2018-10-23 22:24:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.heartlandpower.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.heartlandpower.com.html'
2018-10-23 22:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.wyan.org> (referer: None)
2018-10-23 22:24:41 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.kodiakelectric.com/robots.txt> (referer: None)
2018-10-23 22:24:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.wyan.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.wyan.org.html'
2018-10-23 22:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.kodiakelectric.com> (referer: None)
2018-10-23 22:24:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.kodiakelectric.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.kodiakelectric.com.html'
2018-10-23 22:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cecnet.net/robots.txt> (referer: None)
2018-10-23 22:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.empiredistrict.com/robots.txt> (referer: None)
2018-10-23 22:24:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cecnet.net> (referer: None)
2018-10-23 22:24:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.empiredistrict.com> (referer: None)
2018-10-23 22:24:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cecnet.net> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cecnet.net.html'
2018-10-23 22:24:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.empiredistrict.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.empiredistrict.com.html'
2018-10-23 22:24:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.entergy-louisiana.com/robots.txt> (referer: None)
2018-10-23 22:24:42 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://okcoop.coopwebbuilder2.com/robots.txt> (referer: None)
2018-10-23 22:24:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://okcoop.coopwebbuilder2.com> (referer: None)
2018-10-23 22:24:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://okcoop.coopwebbuilder2.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-okcoop.coopwebbuilder2.com.html'
2018-10-23 22:24:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://pemc.coop/robots.txt> from <GET http://www.pemc.coop/robots.txt>
2018-10-23 22:24:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.entergy-louisiana.com> (referer: None)
2018-10-23 22:24:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://pemc.coop/robots.txt> (referer: None)
2018-10-23 22:24:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.entergy-louisiana.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.entergy-louisiana.com.html'
2018-10-23 22:24:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://pemc.coop/> from <GET http://www.pemc.coop>
2018-10-23 22:24:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.cityofalexandriala.com/robots.txt> from <GET http://www.cityofalexandriala.com/robots.txt>
2018-10-23 22:24:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cityofalexandriala.com/robots.txt> (referer: None)
2018-10-23 22:24:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://pemc.coop/robots.txt> (referer: None)
2018-10-23 22:24:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://pemc.coop/> from <GET http://pemc.coop/>
2018-10-23 22:24:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.cityofalexandriala.com/> from <GET http://www.cityofalexandriala.com>
2018-10-23 22:24:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pemc.coop/> (referer: None)
2018-10-23 22:24:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pemc.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:44 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.swppd.com/robots.txt> (referer: None)
2018-10-23 22:24:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sceg.com/robots.txt> from <GET http://www.sceg.com/robots.txt>
2018-10-23 22:24:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.swppd.com> (referer: None)
2018-10-23 22:24:44 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.danvers.govoffice.com/robots.txt> (referer: None)
2018-10-23 22:24:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.swppd.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.swppd.com.html'
2018-10-23 22:24:44 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.danvers.govoffice.com> (referer: None)
2018-10-23 22:24:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.bpu.com/robots.txt> from <GET http://www.bpu.com/robots.txt>
2018-10-23 22:24:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.danvers.govoffice.com>: HTTP status code is not handled or not allowed
2018-10-23 22:24:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sceg.com/robots.txt> (referer: None)
2018-10-23 22:24:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sceg.com/> from <GET http://www.sceg.com>
2018-10-23 22:24:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.claverack.com/robots.txt> (referer: None)
2018-10-23 22:24:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sceg.com/> (referer: None)
2018-10-23 22:24:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bpu.com/robots.txt> (referer: None)
2018-10-23 22:24:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.sceg.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.emec.com/robots.txt> from <GET http://www.emec.com/robots.txt>
2018-10-23 22:24:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.bpu.com/> from <GET http://www.bpu.com>
2018-10-23 22:24:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.alamedamp.com/robots.txt> (referer: None)
2018-10-23 22:24:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.claverack.com> (referer: None)
2018-10-23 22:24:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.emec.com/robots.txt> (referer: None)
2018-10-23 22:24:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.bpu.com/> (referer: None)
2018-10-23 22:24:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.claverack.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.claverack.com.html'
2018-10-23 22:24:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.emec.com/> from <GET http://www.emec.com>
2018-10-23 22:24:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.mauielectric.com/robots.txt> from <GET http://www.mauielectric.com/robots.txt>
2018-10-23 22:24:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.bpu.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cityofalexandriala.com/> (referer: None)
2018-10-23 22:24:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://bluestemelectric.com/robots.txt> from <GET http://bluestemelectric.com/robots.txt>
2018-10-23 22:24:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cityofalexandriala.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://bluestemelectric.com/robots.txt> (referer: None)
2018-10-23 22:24:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://bluestemelectric.com/> from <GET http://bluestemelectric.com>
2018-10-23 22:24:45 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.mauielectric.com/robots.txt> (referer: None)
2018-10-23 22:24:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.mauielectric.com/> from <GET http://www.mauielectric.com>
2018-10-23 22:24:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.nipsco.com/page-not-found?aspxerrorpath=/robots.txt> from <GET http://www.nipsco.com/robots.txt>
2018-10-23 22:24:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.alamedamp.com> (referer: None)
2018-10-23 22:24:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.nipsco.com/page-not-found?aspxerrorpath=/robots.txt> from <GET http://www.nipsco.com/page-not-found?aspxerrorpath=/robots.txt>
2018-10-23 22:24:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mauielectric.com/> (referer: None)
2018-10-23 22:24:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.alamedamp.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.alamedamp.com.html'
2018-10-23 22:24:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.emec.com/> (referer: None)
2018-10-23 22:24:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.mauielectric.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:46 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.vil.spencerport.ny.us/robots.txt> (referer: None)
2018-10-23 22:24:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.emec.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://bluestemelectric.com/> (referer: None)
2018-10-23 22:24:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.vil.spencerport.ny.us> (referer: None)
2018-10-23 22:24:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bluestemelectric.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.kvremc.com/robots.txt> (referer: None)
2018-10-23 22:24:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.vil.spencerport.ny.us> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.vil.spencerport.ny.us.html'
2018-10-23 22:24:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.granitefallsnc.com/robots.txt> (referer: None) ['partial']
2018-10-23 22:24:46 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://www.granitefallsnc.com>
2018-10-23 22:24:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://billing.georgetown.org/robots.txt> from <GET http://billing.georgetown.org/robots.txt>
2018-10-23 22:24:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.kvremc.com> (referer: None)
2018-10-23 22:24:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.nipsco.com/page-not-found?aspxerrorpath=/robots.txt> (referer: None)
2018-10-23 22:24:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.unitedelectric.coop/robots.txt> (referer: None)
2018-10-23 22:24:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.kvremc.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.kvremc.com.html'
2018-10-23 22:24:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.nipsco.com/> from <GET http://www.nipsco.com>
2018-10-23 22:24:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://georgetown.org/wp-signup.php?new=billing> from <GET https://billing.georgetown.org/robots.txt>
2018-10-23 22:24:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.lpandl.com/robots.txt/> from <GET http://www.lpandl.com/robots.txt>
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.nipsco.com/> (referer: None)
2018-10-23 22:24:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nipsco.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://georgetown.org/wp-signup.php?new=billing> (referer: None)
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.lpandl.com/robots.txt/> (referer: None)
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.westriver.com/robots.txt> (referer: None)
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.unitedelectric.coop> (referer: None)
2018-10-23 22:24:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://billing.georgetown.org/> from <GET http://billing.georgetown.org>
2018-10-23 22:24:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.unitedelectric.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.unitedelectric.coop.html'
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.psrec.coop/robots.txt> (referer: None)
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.preco.org/robots.txt> (referer: None)
2018-10-23 22:24:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://preco.org/> from <GET http://www.preco.org>
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lpandl.com> (referer: None)
2018-10-23 22:24:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.psrec.coop/> from <GET http://www.psrec.coop>
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.westriver.com> (referer: None)
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nixa.com/robots.txt> (referer: None)
2018-10-23 22:24:47 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://www.nixa.com>
2018-10-23 22:24:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.lpandl.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.lpandl.com.html'
2018-10-23 22:24:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.westriver.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.westriver.com.html'
2018-10-23 22:24:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://georgetown.org/wp-signup.php?new=billing> from <GET https://billing.georgetown.org/>
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://preco.org/robots.txt> (referer: None)
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://preco.org/> (referer: None)
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.psrec.coop/> (referer: None)
2018-10-23 22:24:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.rivierautilities.com/robots.txt> from <GET http://www.rivierautilities.com/robots.txt>
2018-10-23 22:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.brookingsutilities.com/robots.txt> (referer: None)
2018-10-23 22:24:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://preco.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.psrec.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rivierautilities.com/robots.txt> (referer: None)
2018-10-23 22:24:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.rivierautilities.com/> from <GET http://www.rivierautilities.com>
2018-10-23 22:24:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.duboisrec.com/robots.txt> (referer: None)
2018-10-23 22:24:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.duboisrec.com> (referer: None)
2018-10-23 22:24:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://georgetown.org/robots.txt> (referer: None)
2018-10-23 22:24:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.brookingsutilities.com> (referer: None)
2018-10-23 22:24:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.pikevillenc.com/robots.txt> (referer: None)
2018-10-23 22:24:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.duboisrec.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.duboisrec.com.html'
2018-10-23 22:24:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rivierautilities.com/> (referer: None)
2018-10-23 22:24:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.pikevillenc.com> (referer: None)
2018-10-23 22:24:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.brookingsutilities.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.brookingsutilities.com.html'
2018-10-23 22:24:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.rivierautilities.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.pikevillenc.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.pikevillenc.com.html'
2018-10-23 22:24:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.baycitymi.org/robots.txt> from <GET http://www.baycitymi.org/robots.txt>
2018-10-23 22:24:48 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://georgetown.org/wp-signup.php?new=billing> (referer: None)
2018-10-23 22:24:48 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.srec.org/robots.txt> (referer: None)
2018-10-23 22:24:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://georgetown.org/wp-signup.php?new=billing>: HTTP status code is not handled or not allowed
2018-10-23 22:24:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofec.com/robots.txt> (referer: None) ['partial']
2018-10-23 22:24:48 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://www.cityofec.com>
2018-10-23 22:24:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.srec.org> (referer: None)
2018-10-23 22:24:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.srec.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.srec.org.html'
2018-10-23 22:24:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://unitil.com/robots.txt> from <GET http://unitil.com/robots.txt>
2018-10-23 22:24:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://NORTHEASTPOW.COM/robots.txt> from <GET http://www.nnppd.com/robots.txt>
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baycitymi.org/robots.txt> (referer: None)
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://NORTHEASTPOW.COM/robots.txt> (referer: None)
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://unitil.com/robots.txt> (referer: None)
2018-10-23 22:24:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://unitil.com/> from <GET http://unitil.com>
2018-10-23 22:24:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://NORTHEASTPOW.COM> from <GET http://www.nnppd.com>
2018-10-23 22:24:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.baycitymi.org/> from <GET http://www.baycitymi.org>
2018-10-23 22:24:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://schuylerdevelopment.net/robots.txt> from <GET http://schuylerdevelopment.net/robots.txt>
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://NORTHEASTPOW.COM/robots.txt> (referer: None)
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cecpower.coop/robots.txt> (referer: None)
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://NORTHEASTPOW.COM> (referer: None)
2018-10-23 22:24:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://NORTHEASTPOW.COM> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-NORTHEASTPOW.COM.html'
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.cityofmangum.com/robots.txt> (referer: None)
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://unitil.com/> (referer: None)
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://schuylerdevelopment.net/robots.txt> (referer: None)
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cecpower.coop> (referer: None)
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofmangum.com> (referer: None)
2018-10-23 22:24:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.schuylerdevelopment.net/> from <GET http://schuylerdevelopment.net>
2018-10-23 22:24:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://unitil.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cecpower.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cecpower.coop.html'
2018-10-23 22:24:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cityofmangum.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cityofmangum.com.html'
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.entergy-mississippi.com/robots.txt> (referer: None)
2018-10-23 22:24:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.fremontne.gov/robots.txt> (referer: None)
2018-10-23 22:24:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.entergy-mississippi.com> (referer: None)
2018-10-23 22:24:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.entergy-mississippi.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.entergy-mississippi.com.html'
2018-10-23 22:24:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.baycitymi.org/> (referer: None)
2018-10-23 22:24:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.schuylerdevelopment.net/robots.txt> (referer: None)
2018-10-23 22:24:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://hotec.coop/robots.txt> from <GET http://hotec.coop/robots.txt>
2018-10-23 22:24:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.baycitymi.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.schuylerdevelopment.net/> (referer: None)
2018-10-23 22:24:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://osage.net/robots.txt> from <GET http://osage.net/robots.txt>
2018-10-23 22:24:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://hotec.coop/robots.txt> (referer: None)
2018-10-23 22:24:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.schuylerdevelopment.net/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://hotec.coop/> from <GET http://hotec.coop>
2018-10-23 22:24:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.pcremc.com/robots.txt> from <GET http://www.pcremc.com/robots.txt>
2018-10-23 22:24:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://osage.net/robots.txt> (referer: None)
2018-10-23 22:24:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pcremc.com/robots.txt> (referer: None)
2018-10-23 22:24:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://osage.net/> from <GET http://osage.net>
2018-10-23 22:24:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.pcremc.com/> from <GET http://www.pcremc.com>
2018-10-23 22:24:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://osage.net/> (referer: None)
2018-10-23 22:24:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.monroenc.org/robots.txt> from <GET http://www.monroenc.org/robots.txt>
2018-10-23 22:24:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://hotec.coop/> (referer: None)
2018-10-23 22:24:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://osage.net/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hotec.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.cityofwauchula.com/robots.txt> from <GET http://www.cityofwauchula.com/robots.txt>
2018-10-23 22:24:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pcremc.com/> (referer: None)
2018-10-23 22:24:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cityofwauchula.com/robots.txt> (referer: None)
2018-10-23 22:24:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pcremc.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.cityofwauchula.com/> from <GET http://www.cityofwauchula.com>
2018-10-23 22:24:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cityofwauchula.com/> (referer: None)
2018-10-23 22:24:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.monroenc.org/robots.txt> (referer: None)
2018-10-23 22:24:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cityofwauchula.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.monroenc.org/> from <GET http://www.monroenc.org>
2018-10-23 22:24:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://kcelectric.coop/robots.txt> (referer: None)
2018-10-23 22:24:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.fremontne.gov> (referer: None)
2018-10-23 22:24:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rockymountainpower.net/robots.txt> (referer: None)
2018-10-23 22:24:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.fremontne.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.fremontne.gov.html'
2018-10-23 22:24:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.westarenergy.com/robots.txt> from <GET http://www.westarenergy.com/robots.txt>
2018-10-23 22:24:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.rockymountainpower.net/index.html> from <GET https://www.rockymountainpower.net>
2018-10-23 22:24:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.les.com/robots.txt> (referer: None)
2018-10-23 22:24:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://kcelectric.coop> (referer: None)
2018-10-23 22:24:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.les.com> (referer: None)
2018-10-23 22:24:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://kcelectric.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-kcelectric.coop.html'
2018-10-23 22:24:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.les.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.les.com.html'
2018-10-23 22:24:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.westarenergy.com/robots.txt> (referer: None)
2018-10-23 22:24:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rockymountainpower.net/index.html> (referer: None)
2018-10-23 22:24:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.maryvillegov.com/robots.txt> (referer: None)
2018-10-23 22:24:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.westarenergy.com/> from <GET http://www.westarenergy.com>
2018-10-23 22:24:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.rockymountainpower.net/index.html> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-index.html.html'
2018-10-23 22:24:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofluverne.org/robots.txt> (referer: None) ['partial']
2018-10-23 22:24:52 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://www.cityofluverne.org>
2018-10-23 22:24:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.monroenc.org/> (referer: None)
2018-10-23 22:24:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.maryvillegov.com> (referer: None)
2018-10-23 22:24:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.monroenc.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.maryvillegov.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.maryvillegov.com.html'
2018-10-23 22:24:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.gallupnm.gov/robots.txt> (referer: None)
2018-10-23 22:24:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.vea.coop/robots.txt> (referer: None)
2018-10-23 22:24:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://adamn.gov/robots.txt> from <GET http://www.adamn.gov/robots.txt>
2018-10-23 22:24:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.westarenergy.com/> (referer: None)
2018-10-23 22:24:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.grda.com/robots.txt> (referer: None)
2018-10-23 22:24:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://vea.coop/> from <GET http://www.vea.coop>
2018-10-23 22:24:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.westarenergy.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.btes.net/robots.txt> (referer: None)
2018-10-23 22:24:53 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://adamn.gov/robots.txt> (referer: None)
2018-10-23 22:24:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://adamn.gov/> from <GET http://www.adamn.gov>
2018-10-23 22:24:53 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://adamn.gov/robots.txt> (referer: None)
2018-10-23 22:24:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.gallupnm.gov> (referer: None)
2018-10-23 22:24:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://adamn.gov/> (referer: None)
2018-10-23 22:24:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.belmont-ma.gov/robots.txt> from <GET http://www.belmont-ma.gov/robots.txt>
2018-10-23 22:24:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.gallupnm.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.gallupnm.gov.html'
2018-10-23 22:24:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://adamn.gov/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.belmont-ma.gov/robots.txt> (referer: None)
2018-10-23 22:24:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.belmont-ma.gov/> from <GET http://www.belmont-ma.gov>
2018-10-23 22:24:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://vea.coop/robots.txt> (referer: None)
2018-10-23 22:24:54 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bolivarelectric.com/robots.txt> (referer: None)
2018-10-23 22:24:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.belmont-ma.gov/> (referer: None)
2018-10-23 22:24:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bolivarelectric.com> (referer: None)
2018-10-23 22:24:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.belmont-ma.gov/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.bolivarelectric.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.bolivarelectric.com.html'
2018-10-23 22:24:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://cmu.com/robots.txt> from <GET http://www.cmu.com/robots.txt>
2018-10-23 22:24:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.warrenminnesota.com/robots.txt> (referer: None) ['partial']
2018-10-23 22:24:54 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://www.warrenminnesota.com>
2018-10-23 22:24:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://clintonsc.govoffice3.com/robots.txt> (referer: None) ['partial']
2018-10-23 22:24:54 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://clintonsc.govoffice3.com>
2018-10-23 22:24:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cmu.com/robots.txt> (referer: None)
2018-10-23 22:24:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://vea.coop/> (referer: None)
2018-10-23 22:24:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://cmu.com/> from <GET http://www.cmu.com>
2018-10-23 22:24:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vea.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://cms3.revize.com/revize/southhavenmi/robots.txt> from <GET http://www.south-haven.com/robots.txt>
2018-10-23 22:24:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.mesaaz.gov/robots.txt> (referer: None)
2018-10-23 22:24:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cmu.com/robots.txt> (referer: None)
2018-10-23 22:24:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.mesaaz.gov/> from <GET http://www.mesaaz.gov>
2018-10-23 22:24:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.grda.com> (referer: None)
2018-10-23 22:24:55 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://cms3.revize.com/revize/southhavenmi/robots.txt> (referer: None)
2018-10-23 22:24:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.grda.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.grda.com.html'
2018-10-23 22:24:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.south-haven.com> (referer: None)
2018-10-23 22:24:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.south-haven.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.south-haven.com.html'
2018-10-23 22:24:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cameron-mo.com/robots.txt> (referer: None)
2018-10-23 22:24:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.wcremc.com/robots.txt> from <GET http://www.wcremc.com/robots.txt>
2018-10-23 22:24:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.mesaaz.gov/> (referer: None)
2018-10-23 22:24:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.wcremc.com/robots.txt> (referer: None)
2018-10-23 22:24:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.mesaaz.gov/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.wcremc.com/> from <GET http://www.wcremc.com>
2018-10-23 22:24:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cameron-mo.com> (referer: None)
2018-10-23 22:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.wcremc.com/> (referer: None)
2018-10-23 22:24:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cameron-mo.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cameron-mo.com.html'
2018-10-23 22:24:56 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://mohawkmunicipalcommission.org/robots.txt> (referer: None)
2018-10-23 22:24:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.wcremc.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:56 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://nuwnotes1.nu.com/robots.txt> (referer: None)
2018-10-23 22:24:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.nu.com> from <GET http://nuwnotes1.nu.com>
2018-10-23 22:24:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.nu.com/robots.txt> from <GET http://www.nu.com/robots.txt>
2018-10-23 22:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://mohawkmunicipalcommission.org> (referer: None)
2018-10-23 22:24:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.cmu.com/> from <GET https://cmu.com/>
2018-10-23 22:24:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://mohawkmunicipalcommission.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-mohawkmunicipalcommission.org.html'
2018-10-23 22:24:56 [scrapy.core.engine] DEBUG: Crawled (301) <GET https://www.nu.com/robots.txt> (referer: None)
2018-10-23 22:24:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.nu.com/> from <GET http://www.nu.com>
2018-10-23 22:24:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.nilesmi.org> from <GET http://www.ci.niles.mi.us/robots.txt>
2018-10-23 22:24:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nilesmi.org> (referer: None)
2018-10-23 22:24:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (meta refresh) to <GET http://www.eversource.com/> from <GET https://www.nu.com/>
2018-10-23 22:24:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.nilesmi.org> from <GET http://www.ci.niles.mi.us>
2018-10-23 22:24:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.eversource.com/robots.txt> from <GET http://www.eversource.com/robots.txt>
2018-10-23 22:24:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.eversource.com/robots.txt> (referer: None)
2018-10-23 22:24:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.eversource.com/content/> from <GET http://www.eversource.com/>
2018-10-23 22:24:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nilesmi.org/robots.txt> (referer: None)
2018-10-23 22:24:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.eversource.com/content/> (referer: None)
2018-10-23 22:24:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nilesmi.org> (referer: None)
2018-10-23 22:24:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.eversource.com/content/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.nilesmi.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.nilesmi.org.html'
2018-10-23 22:24:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://wbmlp.org/robots.txt> from <GET http://www.wbmlp.org/robots.txt>
2018-10-23 22:24:58 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://wbmlp.org/robots.txt> (referer: None)
2018-10-23 22:24:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cmu.com/> (referer: None)
2018-10-23 22:24:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://wbmlp.org/> from <GET http://www.wbmlp.org>
2018-10-23 22:24:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.princeton-il.com/robots.txt> from <GET http://www.princeton-il.com/robots.txt>
2018-10-23 22:24:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.btes.net> (referer: None)
2018-10-23 22:24:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cmu.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:58 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://wbmlp.org/robots.txt> (referer: None)
2018-10-23 22:24:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.btes.net> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.btes.net.html'
2018-10-23 22:24:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://wbmlp.org/> (referer: None)
2018-10-23 22:24:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.kinstonpublicservices.com/robots.txt> (referer: None)
2018-10-23 22:24:58 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.princeton-il.com/robots.txt> (referer: None)
2018-10-23 22:24:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wbmlp.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.princeton-il.com/> from <GET http://www.princeton-il.com>
2018-10-23 22:24:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.kinstonpublicservices.com/150/Public-Services> from <GET http://www.kinstonpublicservices.com>
2018-10-23 22:24:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://cecelec.coopwebbuilder.com/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:24:59 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.jewettcitydpu.com/robots.txt> (referer: None)
2018-10-23 22:24:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.webstercity.com/robots.txt> from <GET http://www.webstercity.com/robots.txt>
2018-10-23 22:24:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jewettcitydpu.com> (referer: None)
2018-10-23 22:24:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.kinstonpublicservices.com/150/Public-Services> (referer: None)
2018-10-23 22:24:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jewettcitydpu.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.jewettcitydpu.com.html'
2018-10-23 22:24:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.webstercity.com/robots.txt> (referer: None)
2018-10-23 22:24:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.kinstonpublicservices.com/150/Public-Services> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-Public-Services.html'
2018-10-23 22:24:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.webstercity.com/> from <GET http://www.webstercity.com>
2018-10-23 22:24:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.princeton-il.com/> (referer: None)
2018-10-23 22:24:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.webstercity.com/> (referer: None)
2018-10-23 22:24:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.princeton-il.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.webstercity.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:24:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.niobrara-electric.org/robots.txt> (referer: None)
2018-10-23 22:25:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.washingtonin.us/robots.txt> (referer: None)
2018-10-23 22:25:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.washingtonin.us> (referer: None)
2018-10-23 22:25:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.washingtonin.us> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.washingtonin.us.html'
2018-10-23 22:25:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.niobrara-electric.org> (referer: None)
2018-10-23 22:25:00 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.aub.org/robots.txt> (referer: None)
2018-10-23 22:25:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.niobrara-electric.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.niobrara-electric.org.html'
2018-10-23 22:25:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jemezcoop.org/robots.txt> (referer: None)
2018-10-23 22:25:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.aub.org> (referer: None)
2018-10-23 22:25:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.aub.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.aub.org.html'
2018-10-23 22:25:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jemezcoop.org> (referer: None)
2018-10-23 22:25:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jemezcoop.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.jemezcoop.org.html'
2018-10-23 22:25:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://bpu.org/robots.txt> from <GET http://www.bpu.org/robots.txt>
2018-10-23 22:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bpu.org/robots.txt> (referer: None)
2018-10-23 22:25:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://bpu.org/> from <GET http://www.bpu.org>
2018-10-23 22:25:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.albemarlenc.gov> from <GET http://www.ci.albemarle.nc.us/robots.txt>
2018-10-23 22:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.albemarlenc.gov> (referer: None)
2018-10-23 22:25:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://www.albemarlenc.gov> from <GET http://www.ci.albemarle.nc.us>
2018-10-23 22:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bpu.org/robots.txt> (referer: None)
2018-10-23 22:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.albemarlenc.gov/robots.txt> (referer: None)
2018-10-23 22:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.albemarlenc.gov> (referer: None)
2018-10-23 22:25:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.albemarlenc.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.albemarlenc.gov.html'
2018-10-23 22:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bpu.org/> (referer: None)
2018-10-23 22:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.psc.state.wv.us/robots.txt> (referer: None)
2018-10-23 22:25:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bpu.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.psc.state.wv.us> (referer: None)
2018-10-23 22:25:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.psc.state.wv.us> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.psc.state.wv.us.html'
2018-10-23 22:25:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.hmlp.com/robots.txt> (referer: None)
2018-10-23 22:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.hmlp.com> (referer: None)
2018-10-23 22:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.alpenapower.com/robots.txt> (referer: None)
2018-10-23 22:25:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.hmlp.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.hmlp.com.html'
2018-10-23 22:25:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.alpenapower.com/> from <GET http://www.alpenapower.com>
2018-10-23 22:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.washingtonelectric.coop/robots.txt> (referer: None)
2018-10-23 22:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.washingtonelectric.coop> (referer: None)
2018-10-23 22:25:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.washingtonelectric.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.washingtonelectric.coop.html'
2018-10-23 22:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.alpenapower.com/> (referer: None)
2018-10-23 22:25:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.alpenapower.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.hamilton-city.org/robots.txt> (referer: None)
2018-10-23 22:25:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.tid.org/robots.txt> (referer: None)
2018-10-23 22:25:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.tid.org/> from <GET http://www.tid.org>
2018-10-23 22:25:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.hamilton-city.org> (referer: None)
2018-10-23 22:25:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.hamilton-city.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.hamilton-city.org.html'
2018-10-23 22:25:06 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.ouc.com/robots.txt> (referer: None)
2018-10-23 22:25:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.ouc.com/> from <GET http://www.ouc.com>
2018-10-23 22:25:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.tid.org/> (referer: None)
2018-10-23 22:25:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tid.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.lakecountrypower.coop/robots.txt> from <GET http://www.lakecountrypower.coop/robots.txt>
2018-10-23 22:25:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.lakecountrypower.coop/robots.txt> (referer: None)
2018-10-23 22:25:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.lakecountrypower.coop/> from <GET http://www.lakecountrypower.coop>
2018-10-23 22:25:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.lakecountrypower.coop/> (referer: None)
2018-10-23 22:25:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.lakecountrypower.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.mpei.com/robots.txt> (referer: None)
2018-10-23 22:25:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.mpei.com> (referer: None)
2018-10-23 22:25:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.mpei.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.mpei.com.html'
2018-10-23 22:25:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.naecoop.com/robots.txt> from <GET http://www.naecoop.com/robots.txt>
2018-10-23 22:25:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.naecoop.com/robots.txt> (referer: None)
2018-10-23 22:25:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.naecoop.com/> from <GET http://www.naecoop.com>
2018-10-23 22:25:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kauai.coopwebbuilder.com/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:25:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.naecoop.com/> (referer: None)
2018-10-23 22:25:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.naecoop.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://vec.org/robots.txt> from <GET http://vec.org/robots.txt>
2018-10-23 22:25:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://vec.org/robots.txt> (referer: None)
2018-10-23 22:25:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ouc.com/> (referer: None)
2018-10-23 22:25:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://vec.org/> from <GET http://vec.org>
2018-10-23 22:25:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ouc.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.wahkiakumpud.org/robots.txt> from <GET http://www.wahkiakumpud.org/robots.txt>
2018-10-23 22:25:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://vec.org/> (referer: None)
2018-10-23 22:25:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.wahkiakumpud.org/robots.txt> (referer: None)
2018-10-23 22:25:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.wahkiakumpud.org/> from <GET http://www.wahkiakumpud.org>
2018-10-23 22:25:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vec.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofmelrose.com/robots.txt> (referer: None) ['partial']
2018-10-23 22:25:15 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET http://www.cityofmelrose.com>
2018-10-23 22:25:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.weci.net/robots.txt> (referer: None)
2018-10-23 22:25:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.wahkiakumpud.org/> (referer: None)
2018-10-23 22:25:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.wahkiakumpud.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.poncacityok.gov/robots.txt> (referer: None)
2018-10-23 22:25:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.poncacityok.gov> (referer: None)
2018-10-23 22:25:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.poncacityok.gov> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.poncacityok.gov.html'
2018-10-23 22:25:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nwec.coopwebbuilder.com/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:25:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://lakeparkmn.com/robots.txt> (referer: None)
2018-10-23 22:25:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://lakeparkmn.com> (referer: None)
2018-10-23 22:25:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://lakeparkmn.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-lakeparkmn.com.html'
2018-10-23 22:25:17 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.oasis.oati.com/robots.txt> (referer: None)
2018-10-23 22:25:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.oasis.oati.com> (referer: None)
2018-10-23 22:25:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.weci.net> (referer: None)
2018-10-23 22:25:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.oasis.oati.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.oasis.oati.com.html'
2018-10-23 22:25:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ieca.coop/robots.txt> (referer: None)
2018-10-23 22:25:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.weci.net> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.weci.net.html'
2018-10-23 22:25:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.steubenrec.com/robots.txt> (referer: None)
2018-10-23 22:25:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ieca.coop> (referer: None)
2018-10-23 22:25:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.ieca.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.ieca.coop.html'
2018-10-23 22:25:18 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.wellsvilleny.com/robots.txt> (referer: None)
2018-10-23 22:25:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.steubenrec.com> (referer: None)
2018-10-23 22:25:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.wellsvilleny.com> (referer: None)
2018-10-23 22:25:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.steubenrec.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.steubenrec.com.html'
2018-10-23 22:25:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.wellsvilleny.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.wellsvilleny.com.html'
2018-10-23 22:25:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.smithfield-nc.com/error/servererror404.htm> from <GET http://www.smithfield-nc.com/robots.txt>
2018-10-23 22:25:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.smithfield-nc.com/error/servererror404.htm> (referer: None)
2018-10-23 22:25:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bedfordrec.com/robots.txt> (referer: None)
2018-10-23 22:25:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bedfordrec.com> (referer: None)
2018-10-23 22:25:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.bedfordrec.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.bedfordrec.com.html'
2018-10-23 22:25:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ks-osagecity2.civicplus.com/robots.txt> (referer: None)
2018-10-23 22:25:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.smithfield-nc.com> (referer: None)
2018-10-23 22:25:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.smithfield-nc.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.smithfield-nc.com.html'
2018-10-23 22:25:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.nueceselectric.org/robots.txt> from <GET http://www.nueceselectric.org/robots.txt>
2018-10-23 22:25:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.nueceselectric.org/robots.txt> (referer: None)
2018-10-23 22:25:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.nueceselectric.org/> from <GET http://www.nueceselectric.org>
2018-10-23 22:25:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ks-osagecity2.civicplus.com> (referer: None)
2018-10-23 22:25:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ks-osagecity2.civicplus.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-ks-osagecity2.civicplus.com.html'
2018-10-23 22:25:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.hwe.coop/robots.txt> from <GET http://www.hwe.coop/robots.txt>
2018-10-23 22:25:20 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.hwe.coop/robots.txt> (referer: None)
2018-10-23 22:25:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.hwe.coop/> from <GET http://www.hwe.coop>
2018-10-23 22:25:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.nueceselectric.org/> (referer: None)
2018-10-23 22:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nueceselectric.org/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.hwecoop.com/robots.txt> from <GET http://www.hwecoop.com/robots.txt>
2018-10-23 22:25:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.hwecoop.com/robots.txt> (referer: None)
2018-10-23 22:25:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.hwecoop.com/> from <GET http://www.hwecoop.com>
2018-10-23 22:25:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.hwe.coop/> (referer: None)
2018-10-23 22:25:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.hwe.coop/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.hwecoop.com/> (referer: None)
2018-10-23 22:25:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.hwecoop.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.laurinburg.org/robots.txt> (referer: None)
2018-10-23 22:25:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.vec.coop/robots.txt> (referer: None)
2018-10-23 22:25:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.laurinburg.org> (referer: None)
2018-10-23 22:25:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.vec.coop> (referer: None)
2018-10-23 22:25:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.laurinburg.org> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.laurinburg.org.html'
2018-10-23 22:25:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.vec.coop> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.vec.coop.html'
2018-10-23 22:25:23 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.cityofharborsprings.com/robots.txt> (referer: None)
2018-10-23 22:25:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.glacierelectric.com/robots.txt> (referer: None)
2018-10-23 22:25:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.glacierelectric.com> (referer: None)
2018-10-23 22:25:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofharborsprings.com> (referer: None)
2018-10-23 22:25:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.glacierelectric.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.glacierelectric.com.html'
2018-10-23 22:25:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cityofharborsprings.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cityofharborsprings.com.html'
2018-10-23 22:25:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.hawaiianelectric.com/robots.txt> from <GET http://www.hawaiianelectric.com/robots.txt>
2018-10-23 22:25:24 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.hawaiianelectric.com/robots.txt> (referer: None)
2018-10-23 22:25:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.hawaiianelectric.com/> from <GET http://www.hawaiianelectric.com>
2018-10-23 22:25:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://houstoncountyelec.com/robots.txt> (referer: None)
2018-10-23 22:25:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://houstoncountyelec.com> (referer: None)
2018-10-23 22:25:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://houstoncountyelec.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-houstoncountyelec.com.html'
2018-10-23 22:25:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.menard.com/robots.txt> (referer: None)
2018-10-23 22:25:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.menard.com> (referer: None)
2018-10-23 22:25:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.menard.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.menard.com.html'
2018-10-23 22:25:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.hawaiianelectric.com/> (referer: None)
2018-10-23 22:25:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.hawaiianelectric.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tcec.coopwebbuilder.com/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:25:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://marshallremc.coopwebbuilder.com/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:25:37 [scrapy.extensions.logstats] INFO: Crawled 752 pages (at 237 pages/min), scraped 0 items (at 0 items/min)
2018-10-23 22:25:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.stfranciskansas.com/robots.txt> from <GET http://www.stfranciskansas.com/robots.txt>
2018-10-23 22:25:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://stfranciskansas.com/robots.txt> from <GET https://www.stfranciskansas.com/robots.txt>
2018-10-23 22:25:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stfranciskansas.com/robots.txt> (referer: None)
2018-10-23 22:25:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.stfranciskansas.com/> from <GET http://www.stfranciskansas.com>
2018-10-23 22:25:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lamarlightandpower.com/robots.txt> (referer: None)
2018-10-23 22:25:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://stfranciskansas.com/> from <GET https://www.stfranciskansas.com/>
2018-10-23 22:25:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lamarlightandpower.com> (referer: None)
2018-10-23 22:25:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.lamarlightandpower.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.lamarlightandpower.com.html'
2018-10-23 22:25:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stfranciskansas.com/robots.txt> (referer: None)
2018-10-23 22:25:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofbellevillekansas.com/robots.txt> (referer: None)
2018-10-23 22:25:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.cityofbellevillekansas.com> (referer: None)
2018-10-23 22:25:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stfranciskansas.com/> (referer: None)
2018-10-23 22:25:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.cityofbellevillekansas.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.cityofbellevillekansas.com.html'
2018-10-23 22:25:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stfranciskansas.com/> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-.html'
2018-10-23 22:25:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://clpower.com/robots.txt> (referer: None)
2018-10-23 22:25:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ci.kinston.nc.us/robots.txt> (referer: None)
2018-10-23 22:25:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://clpower.com> (referer: None)
2018-10-23 22:25:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.ci.kinston.nc.us> (referer: None)
2018-10-23 22:25:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://clpower.com> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-clpower.com.html'
2018-10-23 22:25:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.ci.kinston.nc.us> (referer: None)
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/emigre459/Documents/gitProjects/URDB_Scraping/URDB/URDB/spiders/utility_spider.py", line 35, in parse
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../../Pages/utility-www.ci.kinston.nc.us.html'
2018-10-23 22:25:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.cityofaspen.com/robots.txt> from <GET http://www.aspenpitkin.com/robots.txt>
2018-10-23 22:25:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.cityofaspen.com/robots.txt> (referer: None)
2018-10-23 22:25:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.cityofaspen.com/> from <GET http://www.aspenpitkin.com>
2018-10-23 22:26:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nnec.coopwebbuilder.com/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:26:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://cecelec.coopwebbuilder.com/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:26:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://menard.coopwebbuilder.com/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:26:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kauai.coopwebbuilder.com/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:26:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nwec.coopwebbuilder.com/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:26:37 [scrapy.extensions.logstats] INFO: Crawled 764 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2018-10-23 22:26:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tcec.coopwebbuilder.com/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:26:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://marshallremc.coopwebbuilder.com/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:27:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://southcentralelectric.coopwebbuilder.com/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:27:13 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-10-23 22:27:13 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-10-23 22:27:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nnec.coopwebbuilder.com/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:27:30 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://cecelec.coopwebbuilder.com/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:27:30 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://cecelec.coopwebbuilder.com/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:27:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://menard.coopwebbuilder.com/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:27:37 [scrapy.extensions.logstats] INFO: Crawled 764 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-23 22:27:44 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://kauai.coopwebbuilder.com/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:27:44 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://kauai.coopwebbuilder.com/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:27:48 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://nwec.coopwebbuilder.com/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:27:48 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://nwec.coopwebbuilder.com/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:28:00 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://tcec.coopwebbuilder.com/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:28:00 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://tcec.coopwebbuilder.com/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:28:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://marshallremc.coopwebbuilder.com/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:28:08 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://marshallremc.coopwebbuilder.com/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:28:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://southcentralelectric.coopwebbuilder.com/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:28:37 [scrapy.extensions.logstats] INFO: Crawled 764 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-23 22:28:43 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://nnec.coopwebbuilder.com/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:28:43 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://nnec.coopwebbuilder.com/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:28:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://cecelec.coopwebbuilder.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:28:47 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://menard.coopwebbuilder.com/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:28:47 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://menard.coopwebbuilder.com/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:29:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kauai.coopwebbuilder.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:29:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nwec.coopwebbuilder.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:29:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tcec.coopwebbuilder.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:29:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://marshallremc.coopwebbuilder.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:29:37 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://southcentralelectric.coopwebbuilder.com/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:29:37 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://southcentralelectric.coopwebbuilder.com/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
Traceback (most recent call last):
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/twisted/python/failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Users/emigre459/anaconda3/envs/WebScraping/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:29:37 [scrapy.extensions.logstats] INFO: Crawled 764 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-23 22:29:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nnec.coopwebbuilder.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:30:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://menard.coopwebbuilder.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:30:37 [scrapy.extensions.logstats] INFO: Crawled 764 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-23 22:30:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://southcentralelectric.coopwebbuilder.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-10-23 22:30:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 79,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 14,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 33,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 32,
 'downloader/request_bytes': 258186,
 'downloader/request_count': 1174,
 'downloader/request_method_count/GET': 1174,
 'downloader/response_bytes': 10375299,
 'downloader/response_count': 1109,
 'downloader/response_status_count/200': 675,
 'downloader/response_status_count/301': 234,
 'downloader/response_status_count/302': 105,
 'downloader/response_status_count/307': 5,
 'downloader/response_status_count/401': 2,
 'downloader/response_status_count/403': 3,
 'downloader/response_status_count/404': 85,
 'dupefilter/filtered': 5,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 10, 24, 2, 30, 52, 567454),
 'httperror/response_ignored_count': 8,
 'httperror/response_ignored_status_count/401': 1,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 5,
 'log_count/DEBUG': 1190,
 'log_count/ERROR': 361,
 'log_count/INFO': 23,
 'log_count/WARNING': 1,
 'memusage/max': 122613760,
 'memusage/startup': 86913024,
 'response_received_count': 764,
 'retry/count': 46,
 'retry/max_reached': 19,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 22,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 24,
 'scheduler/dequeued': 581,
 'scheduler/dequeued/memory': 581,
 'scheduler/enqueued': 590,
 'scheduler/enqueued/memory': 590,
 'spider_exceptions/FileNotFoundError': 342,
 'start_time': datetime.datetime(2018, 10, 24, 2, 23, 37, 842010)}
2018-10-23 22:30:52 [scrapy.core.engine] INFO: Spider closed (shutdown)
